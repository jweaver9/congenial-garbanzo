{"version":3,"sources":["../shared/utils.ts","../shared/stream-parts.ts","../streams/ai-stream.ts","../streams/stream-data.ts","../streams/anthropic-stream.ts","../streams/assistant-response.ts","../streams/aws-bedrock-stream.ts","../streams/cohere-stream.ts","../streams/google-generative-ai-stream.ts","../streams/huggingface-stream.ts","../streams/inkeep-stream.ts","../streams/langchain-stream.ts","../streams/mistral-stream.ts","../streams/openai-stream.ts","../streams/replicate-stream.ts","../shared/read-data-stream.ts","../shared/parse-complex-response.ts","../streams/streaming-react-response.ts","../streams/streaming-text-response.ts"],"sourcesContent":["import { customAlphabet } from 'nanoid/non-secure';\nimport {\n  StreamPartType,\n  StreamStringPrefixes,\n  parseStreamPart,\n} from './stream-parts';\n\n// 7-character random string\nexport const nanoid = customAlphabet(\n  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz',\n  7,\n);\n\n// simple decoder signatures:\nfunction createChunkDecoder(): (chunk: Uint8Array | undefined) => string;\nfunction createChunkDecoder(\n  complex: false,\n): (chunk: Uint8Array | undefined) => string;\n// complex decoder signature:\nfunction createChunkDecoder(\n  complex: true,\n): (chunk: Uint8Array | undefined) => StreamPartType[];\n// combined signature for when the client calls this function with a boolean:\nfunction createChunkDecoder(\n  complex?: boolean,\n): (chunk: Uint8Array | undefined) => StreamPartType[] | string;\nfunction createChunkDecoder(complex?: boolean) {\n  const decoder = new TextDecoder();\n\n  if (!complex) {\n    return function (chunk: Uint8Array | undefined): string {\n      if (!chunk) return '';\n      return decoder.decode(chunk, { stream: true });\n    };\n  }\n\n  return function (chunk: Uint8Array | undefined) {\n    const decoded = decoder\n      .decode(chunk, { stream: true })\n      .split('\\n')\n      .filter(line => line !== ''); // splitting leaves an empty string at the end\n\n    return decoded.map(parseStreamPart).filter(Boolean);\n  };\n}\n\nexport { createChunkDecoder };\n\nexport const isStreamStringEqualToType = (\n  type: keyof typeof StreamStringPrefixes,\n  value: string,\n): value is StreamString =>\n  value.startsWith(`${StreamStringPrefixes[type]}:`) && value.endsWith('\\n');\n\nexport type StreamString =\n  `${(typeof StreamStringPrefixes)[keyof typeof StreamStringPrefixes]}:${string}\\n`;\n\n/**\n * A header sent to the client so it knows how to handle parsing the stream (as a deprecated text response or using the new prefixed protocol)\n */\nexport const COMPLEX_HEADER = 'X-Experimental-Stream-Data';\n","import {\n  AssistantMessage,\n  DataMessage,\n  FunctionCall,\n  JSONValue,\n  ToolCall,\n} from './types';\nimport { StreamString } from './utils';\n\nexport interface StreamPart<CODE extends string, NAME extends string, TYPE> {\n  code: CODE;\n  name: NAME;\n  parse: (value: JSONValue) => { type: NAME; value: TYPE };\n}\n\nconst textStreamPart: StreamPart<'0', 'text', string> = {\n  code: '0',\n  name: 'text',\n  parse: (value: JSONValue) => {\n    if (typeof value !== 'string') {\n      throw new Error('\"text\" parts expect a string value.');\n    }\n    return { type: 'text', value };\n  },\n};\n\nconst functionCallStreamPart: StreamPart<\n  '1',\n  'function_call',\n  { function_call: FunctionCall }\n> = {\n  code: '1',\n  name: 'function_call',\n  parse: (value: JSONValue) => {\n    if (\n      value == null ||\n      typeof value !== 'object' ||\n      !('function_call' in value) ||\n      typeof value.function_call !== 'object' ||\n      value.function_call == null ||\n      !('name' in value.function_call) ||\n      !('arguments' in value.function_call) ||\n      typeof value.function_call.name !== 'string' ||\n      typeof value.function_call.arguments !== 'string'\n    ) {\n      throw new Error(\n        '\"function_call\" parts expect an object with a \"function_call\" property.',\n      );\n    }\n\n    return {\n      type: 'function_call',\n      value: value as unknown as { function_call: FunctionCall },\n    };\n  },\n};\n\nconst dataStreamPart: StreamPart<'2', 'data', Array<JSONValue>> = {\n  code: '2',\n  name: 'data',\n  parse: (value: JSONValue) => {\n    if (!Array.isArray(value)) {\n      throw new Error('\"data\" parts expect an array value.');\n    }\n\n    return { type: 'data', value };\n  },\n};\n\nconst errorStreamPart: StreamPart<'3', 'error', string> = {\n  code: '3',\n  name: 'error',\n  parse: (value: JSONValue) => {\n    if (typeof value !== 'string') {\n      throw new Error('\"error\" parts expect a string value.');\n    }\n    return { type: 'error', value };\n  },\n};\n\nconst assistantMessageStreamPart: StreamPart<\n  '4',\n  'assistant_message',\n  AssistantMessage\n> = {\n  code: '4',\n  name: 'assistant_message',\n  parse: (value: JSONValue) => {\n    if (\n      value == null ||\n      typeof value !== 'object' ||\n      !('id' in value) ||\n      !('role' in value) ||\n      !('content' in value) ||\n      typeof value.id !== 'string' ||\n      typeof value.role !== 'string' ||\n      value.role !== 'assistant' ||\n      !Array.isArray(value.content) ||\n      !value.content.every(\n        item =>\n          item != null &&\n          typeof item === 'object' &&\n          'type' in item &&\n          item.type === 'text' &&\n          'text' in item &&\n          item.text != null &&\n          typeof item.text === 'object' &&\n          'value' in item.text &&\n          typeof item.text.value === 'string',\n      )\n    ) {\n      throw new Error(\n        '\"assistant_message\" parts expect an object with an \"id\", \"role\", and \"content\" property.',\n      );\n    }\n\n    return {\n      type: 'assistant_message',\n      value: value as AssistantMessage,\n    };\n  },\n};\n\nconst assistantControlDataStreamPart: StreamPart<\n  '5',\n  'assistant_control_data',\n  {\n    threadId: string;\n    messageId: string;\n  }\n> = {\n  code: '5',\n  name: 'assistant_control_data',\n  parse: (value: JSONValue) => {\n    if (\n      value == null ||\n      typeof value !== 'object' ||\n      !('threadId' in value) ||\n      !('messageId' in value) ||\n      typeof value.threadId !== 'string' ||\n      typeof value.messageId !== 'string'\n    ) {\n      throw new Error(\n        '\"assistant_control_data\" parts expect an object with a \"threadId\" and \"messageId\" property.',\n      );\n    }\n\n    return {\n      type: 'assistant_control_data',\n      value: {\n        threadId: value.threadId,\n        messageId: value.messageId,\n      },\n    };\n  },\n};\n\nconst dataMessageStreamPart: StreamPart<'6', 'data_message', DataMessage> = {\n  code: '6',\n  name: 'data_message',\n  parse: (value: JSONValue) => {\n    if (\n      value == null ||\n      typeof value !== 'object' ||\n      !('role' in value) ||\n      !('data' in value) ||\n      typeof value.role !== 'string' ||\n      value.role !== 'data'\n    ) {\n      throw new Error(\n        '\"data_message\" parts expect an object with a \"role\" and \"data\" property.',\n      );\n    }\n\n    return {\n      type: 'data_message',\n      value: value as DataMessage,\n    };\n  },\n};\n\nconst toolCallStreamPart: StreamPart<\n  '7',\n  'tool_calls',\n  { tool_calls: ToolCall[] }\n> = {\n  code: '7',\n  name: 'tool_calls',\n  parse: (value: JSONValue) => {\n    if (\n      value == null ||\n      typeof value !== 'object' ||\n      !('tool_calls' in value) ||\n      typeof value.tool_calls !== 'object' ||\n      value.tool_calls == null ||\n      !Array.isArray(value.tool_calls) ||\n      value.tool_calls.some(tc => {\n        tc == null ||\n          typeof tc !== 'object' ||\n          !('id' in tc) ||\n          typeof tc.id !== 'string' ||\n          !('type' in tc) ||\n          typeof tc.type !== 'string' ||\n          !('function' in tc) ||\n          tc.function == null ||\n          typeof tc.function !== 'object' ||\n          !('arguments' in tc.function) ||\n          typeof tc.function.name !== 'string' ||\n          typeof tc.function.arguments !== 'string';\n      })\n    ) {\n      throw new Error(\n        '\"tool_calls\" parts expect an object with a ToolCallPayload.',\n      );\n    }\n\n    return {\n      type: 'tool_calls',\n      value: value as unknown as { tool_calls: ToolCall[] },\n    };\n  },\n};\n\nconst messageAnnotationsStreamPart: StreamPart<\n  '8',\n  'message_annotations',\n  Array<JSONValue>\n> = {\n  code: '8',\n  name: 'message_annotations',\n  parse: (value: JSONValue) => {\n    if (!Array.isArray(value)) {\n      throw new Error('\"message_annotations\" parts expect an array value.');\n    }\n\n    return { type: 'message_annotations', value };\n  },\n};\n\nconst streamParts = [\n  textStreamPart,\n  functionCallStreamPart,\n  dataStreamPart,\n  errorStreamPart,\n  assistantMessageStreamPart,\n  assistantControlDataStreamPart,\n  dataMessageStreamPart,\n  toolCallStreamPart,\n  messageAnnotationsStreamPart,\n] as const;\n\n// union type of all stream parts\ntype StreamParts =\n  | typeof textStreamPart\n  | typeof functionCallStreamPart\n  | typeof dataStreamPart\n  | typeof errorStreamPart\n  | typeof assistantMessageStreamPart\n  | typeof assistantControlDataStreamPart\n  | typeof dataMessageStreamPart\n  | typeof toolCallStreamPart\n  | typeof messageAnnotationsStreamPart;\n/**\n * Maps the type of a stream part to its value type.\n */\ntype StreamPartValueType = {\n  [P in StreamParts as P['name']]: ReturnType<P['parse']>['value'];\n};\n\nexport type StreamPartType =\n  | ReturnType<typeof textStreamPart.parse>\n  | ReturnType<typeof functionCallStreamPart.parse>\n  | ReturnType<typeof dataStreamPart.parse>\n  | ReturnType<typeof errorStreamPart.parse>\n  | ReturnType<typeof assistantMessageStreamPart.parse>\n  | ReturnType<typeof assistantControlDataStreamPart.parse>\n  | ReturnType<typeof dataMessageStreamPart.parse>\n  | ReturnType<typeof toolCallStreamPart.parse>\n  | ReturnType<typeof messageAnnotationsStreamPart.parse>;\n\nexport const streamPartsByCode = {\n  [textStreamPart.code]: textStreamPart,\n  [functionCallStreamPart.code]: functionCallStreamPart,\n  [dataStreamPart.code]: dataStreamPart,\n  [errorStreamPart.code]: errorStreamPart,\n  [assistantMessageStreamPart.code]: assistantMessageStreamPart,\n  [assistantControlDataStreamPart.code]: assistantControlDataStreamPart,\n  [dataMessageStreamPart.code]: dataMessageStreamPart,\n  [toolCallStreamPart.code]: toolCallStreamPart,\n  [messageAnnotationsStreamPart.code]: messageAnnotationsStreamPart,\n} as const;\n\n/**\n * The map of prefixes for data in the stream\n *\n * - 0: Text from the LLM response\n * - 1: (OpenAI) function_call responses\n * - 2: custom JSON added by the user using `Data`\n * - 6: (OpenAI) tool_call responses\n *\n * Example:\n * ```\n * 0:Vercel\n * 0:'s\n * 0: AI\n * 0: AI\n * 0: SDK\n * 0: is great\n * 0:!\n * 2: { \"someJson\": \"value\" }\n * 1: {\"function_call\": {\"name\": \"get_current_weather\", \"arguments\": \"{\\\\n\\\\\"location\\\\\": \\\\\"Charlottesville, Virginia\\\\\",\\\\n\\\\\"format\\\\\": \\\\\"celsius\\\\\"\\\\n}\"}}\n * 6: {\"tool_call\": {\"id\": \"tool_0\", \"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"arguments\": \"{\\\\n\\\\\"location\\\\\": \\\\\"Charlottesville, Virginia\\\\\",\\\\n\\\\\"format\\\\\": \\\\\"celsius\\\\\"\\\\n}\"}}}\n *```\n */\nexport const StreamStringPrefixes = {\n  [textStreamPart.name]: textStreamPart.code,\n  [functionCallStreamPart.name]: functionCallStreamPart.code,\n  [dataStreamPart.name]: dataStreamPart.code,\n  [errorStreamPart.name]: errorStreamPart.code,\n  [assistantMessageStreamPart.name]: assistantMessageStreamPart.code,\n  [assistantControlDataStreamPart.name]: assistantControlDataStreamPart.code,\n  [dataMessageStreamPart.name]: dataMessageStreamPart.code,\n  [toolCallStreamPart.name]: toolCallStreamPart.code,\n  [messageAnnotationsStreamPart.name]: messageAnnotationsStreamPart.code,\n} as const;\n\nexport const validCodes = streamParts.map(part => part.code);\n\n/**\n * Parses a stream part from a string.\n *\n * @param line The string to parse.\n * @returns The parsed stream part.\n * @throws An error if the string cannot be parsed.\n */\nexport const parseStreamPart = (line: string): StreamPartType => {\n  const firstSeparatorIndex = line.indexOf(':');\n\n  if (firstSeparatorIndex === -1) {\n    throw new Error('Failed to parse stream string. No separator found.');\n  }\n\n  const prefix = line.slice(0, firstSeparatorIndex);\n\n  if (!validCodes.includes(prefix as keyof typeof streamPartsByCode)) {\n    throw new Error(`Failed to parse stream string. Invalid code ${prefix}.`);\n  }\n\n  const code = prefix as keyof typeof streamPartsByCode;\n\n  const textValue = line.slice(firstSeparatorIndex + 1);\n  const jsonValue: JSONValue = JSON.parse(textValue);\n\n  return streamPartsByCode[code].parse(jsonValue);\n};\n\n/**\n * Prepends a string with a prefix from the `StreamChunkPrefixes`, JSON-ifies it,\n * and appends a new line.\n *\n * It ensures type-safety for the part type and value.\n */\nexport function formatStreamPart<T extends keyof StreamPartValueType>(\n  type: T,\n  value: StreamPartValueType[T],\n): StreamString {\n  const streamPart = streamParts.find(part => part.name === type);\n\n  if (!streamPart) {\n    throw new Error(`Invalid stream part type: ${type}`);\n  }\n\n  return `${streamPart.code}:${JSON.stringify(value)}\\n`;\n}\n","import {\n  createParser,\n  type EventSourceParser,\n  type ParsedEvent,\n  type ReconnectInterval,\n} from 'eventsource-parser';\nimport { OpenAIStreamCallbacks } from './openai-stream';\n\nexport interface FunctionCallPayload {\n  name: string;\n  arguments: Record<string, unknown>;\n}\nexport interface ToolCallPayload {\n  tools: {\n    id: string;\n    type: 'function';\n    func: {\n      name: string;\n      arguments: Record<string, unknown>;\n    };\n  }[];\n}\n\n/**\n * Configuration options and helper callback methods for AIStream stream lifecycle events.\n * @interface\n */\nexport interface AIStreamCallbacksAndOptions {\n  /** `onStart`: Called once when the stream is initialized. */\n  onStart?: () => Promise<void> | void;\n  /** `onCompletion`: Called for each tokenized message. */\n  onCompletion?: (completion: string) => Promise<void> | void;\n  /** `onFinal`: Called once when the stream is closed with the final completion message. */\n  onFinal?: (completion: string) => Promise<void> | void;\n  /** `onToken`: Called for each tokenized message. */\n  onToken?: (token: string) => Promise<void> | void;\n  /** `onText`: Called for each text chunk. */\n  onText?: (text: string) => Promise<void> | void;\n  /**\n   * A flag for enabling the experimental_StreamData class and the new protocol.\n   * @see https://github.com/vercel-labs/ai/pull/425\n   *\n   * When StreamData is rolled out, this will be removed and the new protocol will be used by default.\n   */\n  experimental_streamData?: boolean;\n}\n\n/**\n * Options for the AIStreamParser.\n * @interface\n * @property {string} event - The event (type) from the server side event stream.\n */\nexport interface AIStreamParserOptions {\n  event?: string;\n}\n\n/**\n * Custom parser for AIStream data.\n * @interface\n * @param {string} data - The data to be parsed.\n * @param {AIStreamParserOptions} options - The options for the parser.\n * @returns {string | void} The parsed data or void.\n */\nexport interface AIStreamParser {\n  (data: string, options: AIStreamParserOptions):\n    | string\n    | void\n    | { isText: false; content: string };\n}\n\n/**\n * Creates a TransformStream that parses events from an EventSource stream using a custom parser.\n * @param {AIStreamParser} customParser - Function to handle event data.\n * @returns {TransformStream<Uint8Array, string>} TransformStream parsing events.\n */\nexport function createEventStreamTransformer(\n  customParser?: AIStreamParser,\n): TransformStream<Uint8Array, string | { isText: false; content: string }> {\n  const textDecoder = new TextDecoder();\n  let eventSourceParser: EventSourceParser;\n\n  return new TransformStream({\n    async start(controller): Promise<void> {\n      eventSourceParser = createParser(\n        (event: ParsedEvent | ReconnectInterval) => {\n          if (\n            ('data' in event &&\n              event.type === 'event' &&\n              event.data === '[DONE]') ||\n            // Replicate doesn't send [DONE] but does send a 'done' event\n            // @see https://replicate.com/docs/streaming\n            (event as any).event === 'done'\n          ) {\n            controller.terminate();\n            return;\n          }\n\n          if ('data' in event) {\n            const parsedMessage = customParser\n              ? customParser(event.data, {\n                  event: event.event,\n                })\n              : event.data;\n            if (parsedMessage) controller.enqueue(parsedMessage);\n          }\n        },\n      );\n    },\n\n    transform(chunk) {\n      eventSourceParser.feed(textDecoder.decode(chunk));\n    },\n  });\n}\n\n/**\n * Creates a transform stream that encodes input messages and invokes optional callback functions.\n * The transform stream uses the provided callbacks to execute custom logic at different stages of the stream's lifecycle.\n * - `onStart`: Called once when the stream is initialized.\n * - `onToken`: Called for each tokenized message.\n * - `onCompletion`: Called every time an AIStream completion message is received. This can occur multiple times when using e.g. OpenAI functions\n * - `onFinal`: Called once when the stream is closed with the final completion message.\n *\n * This function is useful when you want to process a stream of messages and perform specific actions during the stream's lifecycle.\n *\n * @param {AIStreamCallbacksAndOptions} [callbacks] - An object containing the callback functions.\n * @return {TransformStream<string, Uint8Array>} A transform stream that encodes input messages as Uint8Array and allows the execution of custom logic through callbacks.\n *\n * @example\n * const callbacks = {\n *   onStart: async () => console.log('Stream started'),\n *   onToken: async (token) => console.log(`Token: ${token}`),\n *   onCompletion: async (completion) => console.log(`Completion: ${completion}`)\n *   onFinal: async () => data.close()\n * };\n * const transformer = createCallbacksTransformer(callbacks);\n */\nexport function createCallbacksTransformer(\n  cb: AIStreamCallbacksAndOptions | OpenAIStreamCallbacks | undefined,\n): TransformStream<string | { isText: false; content: string }, Uint8Array> {\n  const textEncoder = new TextEncoder();\n  let aggregatedResponse = '';\n  const callbacks = cb || {};\n\n  return new TransformStream({\n    async start(): Promise<void> {\n      if (callbacks.onStart) await callbacks.onStart();\n    },\n\n    async transform(message, controller): Promise<void> {\n      const content = typeof message === 'string' ? message : message.content;\n\n      controller.enqueue(textEncoder.encode(content));\n\n      aggregatedResponse += content;\n\n      if (callbacks.onToken) await callbacks.onToken(content);\n      if (callbacks.onText && typeof message === 'string') {\n        await callbacks.onText(message);\n      }\n    },\n\n    async flush(): Promise<void> {\n      const isOpenAICallbacks = isOfTypeOpenAIStreamCallbacks(callbacks);\n      // If it's OpenAICallbacks, it has an experimental_onFunctionCall which means that the createFunctionCallTransformer\n      // will handle calling onComplete.\n      if (callbacks.onCompletion) {\n        await callbacks.onCompletion(aggregatedResponse);\n      }\n\n      if (callbacks.onFinal && !isOpenAICallbacks) {\n        await callbacks.onFinal(aggregatedResponse);\n      }\n    },\n  });\n}\n\nfunction isOfTypeOpenAIStreamCallbacks(\n  callbacks: AIStreamCallbacksAndOptions | OpenAIStreamCallbacks,\n): callbacks is OpenAIStreamCallbacks {\n  return 'experimental_onFunctionCall' in callbacks;\n}\n/**\n * Returns a stateful function that, when invoked, trims leading whitespace\n * from the input text. The trimming only occurs on the first invocation, ensuring that\n * subsequent calls do not alter the input text. This is particularly useful in scenarios\n * where a text stream is being processed and only the initial whitespace should be removed.\n *\n * @return {function(string): string} A function that takes a string as input and returns a string\n * with leading whitespace removed if it is the first invocation; otherwise, it returns the input unchanged.\n *\n * @example\n * const trimStart = trimStartOfStreamHelper();\n * const output1 = trimStart(\"   text\"); // \"text\"\n * const output2 = trimStart(\"   text\"); // \"   text\"\n *\n */\nexport function trimStartOfStreamHelper(): (text: string) => string {\n  let isStreamStart = true;\n\n  return (text: string): string => {\n    if (isStreamStart) {\n      text = text.trimStart();\n      if (text) isStreamStart = false;\n    }\n    return text;\n  };\n}\n\n/**\n * Returns a ReadableStream created from the response, parsed and handled with custom logic.\n * The stream goes through two transformation stages, first parsing the events and then\n * invoking the provided callbacks.\n *\n * For 2xx HTTP responses:\n * - The function continues with standard stream processing.\n *\n * For non-2xx HTTP responses:\n * - If the response body is defined, it asynchronously extracts and decodes the response body.\n * - It then creates a custom ReadableStream to propagate a detailed error message.\n *\n * @param {Response} response - The response.\n * @param {AIStreamParser} customParser - The custom parser function.\n * @param {AIStreamCallbacksAndOptions} callbacks - The callbacks.\n * @return {ReadableStream} The AIStream.\n * @throws Will throw an error if the response is not OK.\n */\nexport function AIStream(\n  response: Response,\n  customParser?: AIStreamParser,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream<Uint8Array> {\n  if (!response.ok) {\n    if (response.body) {\n      const reader = response.body.getReader();\n      return new ReadableStream({\n        async start(controller) {\n          const { done, value } = await reader.read();\n          if (!done) {\n            const errorText = new TextDecoder().decode(value);\n            controller.error(new Error(`Response error: ${errorText}`));\n          }\n        },\n      });\n    } else {\n      return new ReadableStream({\n        start(controller) {\n          controller.error(new Error('Response error: No response body'));\n        },\n      });\n    }\n  }\n\n  const responseBodyStream = response.body || createEmptyReadableStream();\n\n  return responseBodyStream\n    .pipeThrough(createEventStreamTransformer(customParser))\n    .pipeThrough(createCallbacksTransformer(callbacks));\n}\n\n// outputs lines like\n// 0: chunk\n// 0: more chunk\n// 1: a fct call\n// z: added data from Data\n\n/**\n * Creates an empty ReadableStream that immediately closes upon creation.\n * This function is used as a fallback for creating a ReadableStream when the response body is null or undefined,\n * ensuring that the subsequent pipeline processing doesn't fail due to a lack of a stream.\n *\n * @returns {ReadableStream} An empty and closed ReadableStream instance.\n */\nfunction createEmptyReadableStream(): ReadableStream {\n  return new ReadableStream({\n    start(controller) {\n      controller.close();\n    },\n  });\n}\n\n/**\n * Implements ReadableStream.from(asyncIterable), which isn't documented in MDN and isn't implemented in node.\n * https://github.com/whatwg/streams/commit/8d7a0bf26eb2cc23e884ddbaac7c1da4b91cf2bc\n */\nexport function readableFromAsyncIterable<T>(iterable: AsyncIterable<T>) {\n  let it = iterable[Symbol.asyncIterator]();\n  return new ReadableStream<T>({\n    async pull(controller) {\n      const { done, value } = await it.next();\n      if (done) controller.close();\n      else controller.enqueue(value);\n    },\n\n    async cancel(reason) {\n      await it.return?.(reason);\n    },\n  });\n}\n","import { formatStreamPart } from '../shared/stream-parts';\nimport { JSONValue } from '../shared/types';\n\n/**\n * A stream wrapper to send custom JSON-encoded data back to the client.\n */\nexport class experimental_StreamData {\n  private encoder = new TextEncoder();\n\n  private controller: TransformStreamDefaultController<Uint8Array> | null =\n    null;\n  public stream: TransformStream<Uint8Array, Uint8Array>;\n\n  // closing the stream is synchronous, but we want to return a promise\n  // in case we're doing async work\n  private isClosedPromise: Promise<void> | null = null;\n  private isClosedPromiseResolver: undefined | (() => void) = undefined;\n  private isClosed: boolean = false;\n\n  // array to store appended data\n  private data: JSONValue[] = [];\n  private messageAnnotations: JSONValue[] = [];\n\n  constructor() {\n    this.isClosedPromise = new Promise(resolve => {\n      this.isClosedPromiseResolver = resolve;\n    });\n\n    const self = this;\n    this.stream = new TransformStream({\n      start: async controller => {\n        self.controller = controller;\n      },\n      transform: async (chunk, controller) => {\n        // add buffered data to the stream\n        if (self.data.length > 0) {\n          const encodedData = self.encoder.encode(\n            formatStreamPart('data', self.data),\n          );\n          self.data = [];\n          controller.enqueue(encodedData);\n        }\n\n        if (self.messageAnnotations.length) {\n          const encodedMessageAnnotations = self.encoder.encode(\n            formatStreamPart('message_annotations', self.messageAnnotations),\n          );\n          self.messageAnnotations = [];\n          controller.enqueue(encodedMessageAnnotations);\n        }\n\n        controller.enqueue(chunk);\n      },\n      async flush(controller) {\n        // Show a warning during dev if the data stream is hanging after 3 seconds.\n        const warningTimeout =\n          process.env.NODE_ENV === 'development'\n            ? setTimeout(() => {\n                console.warn(\n                  'The data stream is hanging. Did you forget to close it with `data.close()`?',\n                );\n              }, 3000)\n            : null;\n\n        await self.isClosedPromise;\n\n        if (warningTimeout !== null) {\n          clearTimeout(warningTimeout);\n        }\n\n        if (self.data.length) {\n          const encodedData = self.encoder.encode(\n            formatStreamPart('data', self.data),\n          );\n          controller.enqueue(encodedData);\n        }\n\n        if (self.messageAnnotations.length) {\n          const encodedData = self.encoder.encode(\n            formatStreamPart('message_annotations', self.messageAnnotations),\n          );\n          controller.enqueue(encodedData);\n        }\n      },\n    });\n  }\n\n  async close(): Promise<void> {\n    if (this.isClosed) {\n      throw new Error('Data Stream has already been closed.');\n    }\n\n    if (!this.controller) {\n      throw new Error('Stream controller is not initialized.');\n    }\n\n    this.isClosedPromiseResolver?.();\n    this.isClosed = true;\n  }\n\n  append(value: JSONValue): void {\n    if (this.isClosed) {\n      throw new Error('Data Stream has already been closed.');\n    }\n\n    this.data.push(value);\n  }\n\n  appendMessageAnnotation(value: JSONValue): void {\n    if (this.isClosed) {\n      throw new Error('Data Stream has already been closed.');\n    }\n\n    this.messageAnnotations.push(value);\n  }\n}\n\n/**\n * A TransformStream for LLMs that do not have their own transform stream handlers managing encoding (e.g. OpenAIStream has one for function call handling).\n * This assumes every chunk is a 'text' chunk.\n */\nexport function createStreamDataTransformer(\n  experimental_streamData: boolean | undefined,\n) {\n  if (!experimental_streamData) {\n    return new TransformStream({\n      transform: async (chunk, controller) => {\n        controller.enqueue(chunk);\n      },\n    });\n  }\n  const encoder = new TextEncoder();\n  const decoder = new TextDecoder();\n  return new TransformStream({\n    transform: async (chunk, controller) => {\n      const message = decoder.decode(chunk);\n      controller.enqueue(encoder.encode(formatStreamPart('text', message)));\n    },\n  });\n}\n","import {\n  AIStream,\n  readableFromAsyncIterable,\n  type AIStreamCallbacksAndOptions,\n  createCallbacksTransformer,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\n// from anthropic sdk (Completion)\ninterface CompletionChunk {\n  /**\n   * Unique object identifier.\n   *\n   * The format and length of IDs may change over time.\n   */\n  id: string;\n\n  /**\n   * The resulting completion up to and excluding the stop sequences.\n   */\n  completion: string;\n\n  /**\n   * The model that handled the request.\n   */\n  model: string;\n\n  /**\n   * The reason that we stopped.\n   *\n   * This may be one the following values:\n   *\n   * - `\"stop_sequence\"`: we reached a stop sequence — either provided by you via the\n   *   `stop_sequences` parameter, or a stop sequence built into the model\n   * - `\"max_tokens\"`: we exceeded `max_tokens_to_sample` or the model's maximum\n   */\n  stop_reason: string | null;\n\n  /**\n   * Object type.\n   *\n   * For Text Completions, this is always `\"completion\"`.\n   */\n  type: 'completion';\n}\n\ninterface StreamError {\n  error: {\n    type: string;\n    message: string;\n  };\n}\n\ninterface StreamPing {}\n\ntype StreamData = CompletionChunk | StreamError | StreamPing;\n\ninterface Message {\n  id: string;\n  content: Array<ContentBlock>;\n  model: string;\n  role: 'assistant';\n  stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | null;\n  stop_sequence: string | null;\n  type: 'message';\n}\n\ninterface ContentBlock {\n  text: string;\n  type: 'text';\n}\n\ninterface TextDelta {\n  text: string;\n  type: 'text_delta';\n}\n\ninterface ContentBlockDeltaEvent {\n  delta: TextDelta;\n  index: number;\n  type: 'content_block_delta';\n}\n\ninterface ContentBlockStartEvent {\n  content_block: ContentBlock;\n  index: number;\n  type: 'content_block_start';\n}\n\ninterface ContentBlockStopEvent {\n  index: number;\n  type: 'content_block_stop';\n}\n\ninterface MessageDeltaEventDelta {\n  stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | null;\n  stop_sequence: string | null;\n}\n\ninterface MessageDeltaEvent {\n  delta: MessageDeltaEventDelta;\n  type: 'message_delta';\n}\n\ntype MessageStreamEvent =\n  | MessageStartEvent\n  | MessageDeltaEvent\n  | MessageStopEvent\n  | ContentBlockStartEvent\n  | ContentBlockDeltaEvent\n  | ContentBlockStopEvent;\n\ninterface MessageStartEvent {\n  message: Message;\n  type: 'message_start';\n}\n\ninterface MessageStopEvent {\n  type: 'message_stop';\n}\n\nfunction parseAnthropicStream(): (data: string) => string | void {\n  let previous = '';\n\n  return data => {\n    const json = JSON.parse(data as string) as StreamData;\n\n    // error event\n    if ('error' in json) {\n      throw new Error(`${json.error.type}: ${json.error.message}`);\n    }\n\n    // ping event\n    if (!('completion' in json)) {\n      return;\n    }\n\n    // On API versions older than 2023-06-01,\n    // Anthropic's `completion` field is cumulative unlike OpenAI's\n    // deltas. In order to compute the delta, we must slice out the text\n    // we previously received.\n    const text = json.completion;\n    if (\n      !previous ||\n      (text.length > previous.length && text.startsWith(previous))\n    ) {\n      const delta = text.slice(previous.length);\n      previous = text;\n\n      return delta;\n    }\n\n    return text;\n  };\n}\n\nasync function* streamable(\n  stream: AsyncIterable<CompletionChunk> | AsyncIterable<MessageStreamEvent>,\n) {\n  for await (const chunk of stream) {\n    if ('completion' in chunk) {\n      // completion stream\n      const text = chunk.completion;\n      if (text) yield text;\n    } else if ('delta' in chunk) {\n      // messge stream\n      const { delta } = chunk;\n      if ('text' in delta) {\n        const text = delta.text;\n        if (text) yield text;\n      }\n    }\n  }\n}\n\n/**\n * Accepts either a fetch Response from the Anthropic `POST /v1/complete` endpoint,\n * or the return value of `await client.completions.create({ stream: true })`\n * from the `@anthropic-ai/sdk` package.\n */\nexport function AnthropicStream(\n  res:\n    | Response\n    | AsyncIterable<CompletionChunk>\n    | AsyncIterable<MessageStreamEvent>,\n  cb?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  if (Symbol.asyncIterator in res) {\n    return readableFromAsyncIterable(streamable(res))\n      .pipeThrough(createCallbacksTransformer(cb))\n      .pipeThrough(createStreamDataTransformer(cb?.experimental_streamData));\n  } else {\n    return AIStream(res, parseAnthropicStream(), cb).pipeThrough(\n      createStreamDataTransformer(cb?.experimental_streamData),\n    );\n  }\n}\n","import { formatStreamPart } from '../shared/stream-parts';\nimport { AssistantMessage, DataMessage } from '../shared/types';\n\ntype AssistantResponseSettings = {\n  threadId: string;\n  messageId: string;\n};\n\ntype AssistantResponseCallback = (stream: {\n  threadId: string;\n  messageId: string;\n  sendMessage: (message: AssistantMessage) => void;\n  sendDataMessage: (message: DataMessage) => void;\n}) => Promise<void>;\n\nexport function experimental_AssistantResponse(\n  { threadId, messageId }: AssistantResponseSettings,\n  process: AssistantResponseCallback,\n): Response {\n  const stream = new ReadableStream({\n    async start(controller) {\n      const textEncoder = new TextEncoder();\n\n      const sendMessage = (message: AssistantMessage) => {\n        controller.enqueue(\n          textEncoder.encode(formatStreamPart('assistant_message', message)),\n        );\n      };\n\n      const sendDataMessage = (message: DataMessage) => {\n        controller.enqueue(\n          textEncoder.encode(formatStreamPart('data_message', message)),\n        );\n      };\n\n      const sendError = (errorMessage: string) => {\n        controller.enqueue(\n          textEncoder.encode(formatStreamPart('error', errorMessage)),\n        );\n      };\n\n      // send the threadId and messageId as the first message:\n      controller.enqueue(\n        textEncoder.encode(\n          formatStreamPart('assistant_control_data', {\n            threadId,\n            messageId,\n          }),\n        ),\n      );\n\n      try {\n        await process({\n          threadId,\n          messageId,\n          sendMessage,\n          sendDataMessage,\n        });\n      } catch (error) {\n        sendError((error as any).message ?? `${error}`);\n      } finally {\n        controller.close();\n      }\n    },\n    pull(controller) {},\n    cancel() {},\n  });\n\n  return new Response(stream, {\n    status: 200,\n    headers: {\n      'Content-Type': 'text/plain; charset=utf-8',\n    },\n  });\n}\n","import {\n  AIStreamCallbacksAndOptions,\n  createCallbacksTransformer,\n  readableFromAsyncIterable,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\ninterface AWSBedrockResponse {\n  body?: AsyncIterable<{\n    chunk?: { bytes?: Uint8Array };\n  }>;\n}\n\nasync function* asDeltaIterable(\n  response: AWSBedrockResponse,\n  extractTextDeltaFromChunk: (chunk: any) => string,\n) {\n  const decoder = new TextDecoder();\n  for await (const chunk of response.body ?? []) {\n    const bytes = chunk.chunk?.bytes;\n\n    if (bytes != null) {\n      const chunkText = decoder.decode(bytes);\n      const chunkJSON = JSON.parse(chunkText);\n      const delta = extractTextDeltaFromChunk(chunkJSON);\n\n      if (delta != null) {\n        yield delta;\n      }\n    }\n  }\n}\n\nexport function AWSBedrockAnthropicStream(\n  response: AWSBedrockResponse,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  return AWSBedrockStream(response, callbacks, chunk => chunk.completion);\n}\n\nexport function AWSBedrockCohereStream(\n  response: AWSBedrockResponse,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  return AWSBedrockStream(\n    response,\n    callbacks,\n    // As of 2023-11-17, Bedrock does not support streaming for Cohere,\n    // so we take the full generation:\n    chunk => chunk.generations?.[0]?.text,\n  );\n}\n\nexport function AWSBedrockLlama2Stream(\n  response: AWSBedrockResponse,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  return AWSBedrockStream(response, callbacks, chunk => chunk.generation);\n}\n\nexport function AWSBedrockStream(\n  response: AWSBedrockResponse,\n  callbacks: AIStreamCallbacksAndOptions | undefined,\n  extractTextDeltaFromChunk: (chunk: any) => string,\n) {\n  return readableFromAsyncIterable(\n    asDeltaIterable(response, extractTextDeltaFromChunk),\n  )\n    .pipeThrough(createCallbacksTransformer(callbacks))\n    .pipeThrough(\n      createStreamDataTransformer(callbacks?.experimental_streamData),\n    );\n}\n","import {\n  type AIStreamCallbacksAndOptions,\n  createCallbacksTransformer,\n  readableFromAsyncIterable,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\nconst utf8Decoder = new TextDecoder('utf-8');\n\n// Full types\n// @see: https://github.com/cohere-ai/cohere-typescript/blob/c2eceb4a845098240ba0bc44e3787ccf75e268e8/src/api/types/StreamedChatResponse.ts\ninterface StreamChunk {\n  text?: string;\n  eventType:\n    | 'stream-start'\n    | 'search-queries-generation'\n    | 'search-results'\n    | 'text-generation'\n    | 'citation-generation'\n    | 'stream-end';\n}\n\nasync function processLines(\n  lines: string[],\n  controller: ReadableStreamDefaultController<string>,\n) {\n  for (const line of lines) {\n    const { text, is_finished } = JSON.parse(line);\n\n    // closing the reader is handed in readAndProcessLines\n    if (!is_finished) {\n      controller.enqueue(text);\n    }\n  }\n}\n\nasync function readAndProcessLines(\n  reader: ReadableStreamDefaultReader<Uint8Array>,\n  controller: ReadableStreamDefaultController<string>,\n) {\n  let segment = '';\n\n  while (true) {\n    const { value: chunk, done } = await reader.read();\n    if (done) {\n      break;\n    }\n\n    segment += utf8Decoder.decode(chunk, { stream: true });\n\n    const linesArray = segment.split(/\\r\\n|\\n|\\r/g);\n    segment = linesArray.pop() || '';\n\n    await processLines(linesArray, controller);\n  }\n\n  if (segment) {\n    const linesArray = [segment];\n    await processLines(linesArray, controller);\n  }\n\n  controller.close();\n}\n\nfunction createParser(res: Response) {\n  const reader = res.body?.getReader();\n\n  return new ReadableStream<string>({\n    async start(controller): Promise<void> {\n      if (!reader) {\n        controller.close();\n        return;\n      }\n\n      await readAndProcessLines(reader, controller);\n    },\n  });\n}\n\nasync function* streamable(stream: AsyncIterable<StreamChunk>) {\n  for await (const chunk of stream) {\n    if (chunk.eventType === 'text-generation') {\n      const text = chunk.text;\n      if (text) yield text;\n    }\n  }\n}\n\nexport function CohereStream(\n  reader: Response | AsyncIterable<StreamChunk>,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  if (Symbol.asyncIterator in reader) {\n    return readableFromAsyncIterable(streamable(reader))\n      .pipeThrough(createCallbacksTransformer(callbacks))\n      .pipeThrough(\n        createStreamDataTransformer(callbacks?.experimental_streamData),\n      );\n  } else {\n    return createParser(reader)\n      .pipeThrough(createCallbacksTransformer(callbacks))\n      .pipeThrough(\n        createStreamDataTransformer(callbacks?.experimental_streamData),\n      );\n  }\n}\n","import {\n  createCallbacksTransformer,\n  readableFromAsyncIterable,\n  type AIStreamCallbacksAndOptions,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\ninterface GenerateContentResponse {\n  candidates?: GenerateContentCandidate[];\n}\n\ninterface GenerateContentCandidate {\n  index: number;\n  content: Content;\n}\n\ninterface Content {\n  role: string;\n  parts: Part[];\n}\n\ntype Part = TextPart | InlineDataPart;\n\ninterface InlineDataPart {\n  text?: never;\n}\n\ninterface TextPart {\n  text: string;\n  inlineData?: never;\n}\n\nasync function* streamable(response: {\n  stream: AsyncIterable<GenerateContentResponse>;\n}) {\n  for await (const chunk of response.stream) {\n    const parts = chunk.candidates?.[0]?.content?.parts;\n\n    if (parts === undefined) {\n      continue;\n    }\n\n    const firstPart = parts[0];\n\n    if (typeof firstPart.text === 'string') {\n      yield firstPart.text;\n    }\n  }\n}\n\nexport function GoogleGenerativeAIStream(\n  response: {\n    stream: AsyncIterable<GenerateContentResponse>;\n  },\n  cb?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  return readableFromAsyncIterable(streamable(response))\n    .pipeThrough(createCallbacksTransformer(cb))\n    .pipeThrough(createStreamDataTransformer(cb?.experimental_streamData));\n}\n","import {\n  type AIStreamCallbacksAndOptions,\n  createCallbacksTransformer,\n  trimStartOfStreamHelper,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\nfunction createParser(res: AsyncGenerator<any>) {\n  const trimStartOfStream = trimStartOfStreamHelper();\n  return new ReadableStream<string>({\n    async pull(controller): Promise<void> {\n      const { value, done } = await res.next();\n\n      if (done) {\n        controller.close();\n        return;\n      }\n\n      const text = trimStartOfStream(value.token?.text ?? '');\n      if (!text) return;\n\n      // some HF models return generated_text instead of a real ending token\n      if (value.generated_text != null && value.generated_text.length > 0) {\n        return;\n      }\n\n      // <|endoftext|> is for https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\n      // <|end|> is for https://huggingface.co/HuggingFaceH4/starchat-beta\n      // </s> is also often last token in the stream depending on the model\n      if (text === '</s>' || text === '<|endoftext|>' || text === '<|end|>') {\n        return;\n      }\n\n      controller.enqueue(text);\n    },\n  });\n}\n\nexport function HuggingFaceStream(\n  res: AsyncGenerator<any>,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  return createParser(res)\n    .pipeThrough(createCallbacksTransformer(callbacks))\n    .pipeThrough(\n      createStreamDataTransformer(callbacks?.experimental_streamData),\n    );\n}\n","// packages/core/streams/inkeep-stream.ts\nimport {\n  AIStream,\n  type AIStreamCallbacksAndOptions,\n  AIStreamParser,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\nexport type InkeepOnFinalMetadata = {\n  chat_session_id: string;\n  records_cited: any;\n};\n\nexport type InkeepChatResultCallbacks = {\n  onFinal?: (\n    completion: string,\n    metadata?: InkeepOnFinalMetadata,\n  ) => Promise<void> | void;\n  onRecordsCited?: (\n    records_cited: InkeepOnFinalMetadata['records_cited'],\n  ) => void;\n};\n\nexport type InkeepAIStreamCallbacksAndOptions = AIStreamCallbacksAndOptions &\n  InkeepChatResultCallbacks;\n\nexport function InkeepStream(\n  res: Response,\n  callbacks?: InkeepAIStreamCallbacksAndOptions,\n): ReadableStream {\n  if (!res.body) {\n    throw new Error('Response body is null');\n  }\n\n  let chat_session_id = '';\n  let records_cited: any;\n\n  const inkeepEventParser: AIStreamParser = (data: string, options) => {\n    const { event } = options;\n\n    if (event === 'records_cited') {\n      records_cited = JSON.parse(data) as any;\n      callbacks?.onRecordsCited?.(records_cited);\n    }\n\n    if (event === 'message_chunk') {\n      const inkeepMessageChunk = JSON.parse(data);\n      chat_session_id = inkeepMessageChunk.chat_session_id ?? chat_session_id;\n      return inkeepMessageChunk.content_chunk;\n    }\n    return;\n  };\n\n  let { onRecordsCited, ...passThroughCallbacks } = callbacks || {};\n\n  // extend onFinal callback with Inkeep specific metadata\n  passThroughCallbacks = {\n    ...passThroughCallbacks,\n    onFinal: completion => {\n      const inkeepOnFinalMetadata: InkeepOnFinalMetadata = {\n        chat_session_id,\n        records_cited,\n      };\n      callbacks?.onFinal?.(completion, inkeepOnFinalMetadata);\n    },\n  };\n\n  return AIStream(res, inkeepEventParser, passThroughCallbacks).pipeThrough(\n    createStreamDataTransformer(passThroughCallbacks?.experimental_streamData),\n  );\n}\n","import {\n  type AIStreamCallbacksAndOptions,\n  createCallbacksTransformer,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\nexport function LangChainStream(callbacks?: AIStreamCallbacksAndOptions) {\n  const stream = new TransformStream();\n  const writer = stream.writable.getWriter();\n\n  const runs = new Set();\n\n  const handleError = async (e: Error, runId: string) => {\n    runs.delete(runId);\n    await writer.ready;\n    await writer.abort(e);\n  };\n\n  const handleStart = async (runId: string) => {\n    runs.add(runId);\n  };\n\n  const handleEnd = async (runId: string) => {\n    runs.delete(runId);\n\n    if (runs.size === 0) {\n      await writer.ready;\n      await writer.close();\n    }\n  };\n\n  return {\n    stream: stream.readable\n      .pipeThrough(createCallbacksTransformer(callbacks))\n      .pipeThrough(\n        createStreamDataTransformer(callbacks?.experimental_streamData),\n      ),\n    writer,\n    handlers: {\n      handleLLMNewToken: async (token: string) => {\n        await writer.ready;\n        await writer.write(token);\n      },\n      handleLLMStart: async (_llm: any, _prompts: string[], runId: string) => {\n        handleStart(runId);\n      },\n      handleLLMEnd: async (_output: any, runId: string) => {\n        await handleEnd(runId);\n      },\n      handleLLMError: async (e: Error, runId: string) => {\n        await handleError(e, runId);\n      },\n      handleChainStart: async (_chain: any, _inputs: any, runId: string) => {\n        handleStart(runId);\n      },\n      handleChainEnd: async (_outputs: any, runId: string) => {\n        await handleEnd(runId);\n      },\n      handleChainError: async (e: Error, runId: string) => {\n        await handleError(e, runId);\n      },\n      handleToolStart: async (_tool: any, _input: string, runId: string) => {\n        handleStart(runId);\n      },\n      handleToolEnd: async (_output: string, runId: string) => {\n        await handleEnd(runId);\n      },\n      handleToolError: async (e: Error, runId: string) => {\n        await handleError(e, runId);\n      },\n    },\n  };\n}\n","import { ChatCompletionResponseChunk } from '@mistralai/mistralai';\nimport {\n  createCallbacksTransformer,\n  readableFromAsyncIterable,\n  type AIStreamCallbacksAndOptions,\n} from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\nasync function* streamable(stream: AsyncIterable<ChatCompletionResponseChunk>) {\n  for await (const chunk of stream) {\n    const content = chunk.choices[0]?.delta?.content;\n\n    if (content === undefined || content === '') {\n      continue;\n    }\n\n    yield content;\n  }\n}\n\nexport function MistralStream(\n  response: AsyncGenerator<ChatCompletionResponseChunk, void, unknown>,\n  callbacks?: AIStreamCallbacksAndOptions,\n): ReadableStream {\n  const stream = readableFromAsyncIterable(streamable(response));\n  return stream\n    .pipeThrough(createCallbacksTransformer(callbacks))\n    .pipeThrough(\n      createStreamDataTransformer(callbacks?.experimental_streamData),\n    );\n}\n","import { formatStreamPart } from '../shared/stream-parts';\nimport {\n  CreateMessage,\n  FunctionCall,\n  JSONValue,\n  ToolCall,\n} from '../shared/types';\nimport { createChunkDecoder } from '../shared/utils';\n\nimport {\n  AIStream,\n  trimStartOfStreamHelper,\n  type AIStreamCallbacksAndOptions,\n  FunctionCallPayload,\n  readableFromAsyncIterable,\n  createCallbacksTransformer,\n  ToolCallPayload,\n} from './ai-stream';\nimport { AzureChatCompletions } from './azure-openai-types';\nimport { createStreamDataTransformer } from './stream-data';\n\nexport type OpenAIStreamCallbacks = AIStreamCallbacksAndOptions & {\n  /**\n   * @example\n   * ```js\n   * const response = await openai.chat.completions.create({\n   *   model: 'gpt-3.5-turbo-0613',\n   *   stream: true,\n   *   messages,\n   *   functions,\n   * })\n   *\n   * const stream = OpenAIStream(response, {\n   *   experimental_onFunctionCall: async (functionCallPayload, createFunctionCallMessages) => {\n   *     // ... run your custom logic here\n   *     const result = await myFunction(functionCallPayload)\n   *\n   *     // Ask for another completion, or return a string to send to the client as an assistant message.\n   *     return await openai.chat.completions.create({\n   *       model: 'gpt-3.5-turbo-0613',\n   *       stream: true,\n   *       // Append the relevant \"assistant\" and \"function\" call messages\n   *       messages: [...messages, ...createFunctionCallMessages(result)],\n   *       functions,\n   *     })\n   *   }\n   * })\n   * ```\n   */\n  experimental_onFunctionCall?: (\n    functionCallPayload: FunctionCallPayload,\n    createFunctionCallMessages: (\n      functionCallResult: JSONValue,\n    ) => CreateMessage[],\n  ) => Promise<\n    Response | undefined | void | string | AsyncIterableOpenAIStreamReturnTypes\n  >;\n  /**\n   * @example\n   * ```js\n   * const response = await openai.chat.completions.create({\n   *   model: 'gpt-3.5-turbo-1106', // or gpt-4-1106-preview\n   *   stream: true,\n   *   messages,\n   *   tools,\n   *   tool_choice: \"auto\", // auto is default, but we'll be explicit\n   * })\n   *\n   * const stream = OpenAIStream(response, {\n   *   experimental_onToolCall: async (toolCallPayload, appendToolCallMessages) => {\n   *    let messages: CreateMessage[] = []\n   *    //   There might be multiple tool calls, so we need to iterate through them\n   *    for (const tool of toolCallPayload.tools) {\n   *     // ... run your custom logic here\n   *     const result = await myFunction(tool.function)\n   *    // Append the relevant \"assistant\" and \"tool\" call messages\n   *     appendToolCallMessage({tool_call_id:tool.id, function_name:tool.function.name, tool_call_result:result})\n   *    }\n   *     // Ask for another completion, or return a string to send to the client as an assistant message.\n   *     return await openai.chat.completions.create({\n   *       model: 'gpt-3.5-turbo-1106', // or gpt-4-1106-preview\n   *       stream: true,\n   *       // Append the results messages, calling appendToolCallMessage without\n   *       // any arguments will jsut return the accumulated messages\n   *       messages: [...messages, ...appendToolCallMessage()],\n   *       tools,\n   *        tool_choice: \"auto\", // auto is default, but we'll be explicit\n   *     })\n   *   }\n   * })\n   * ```\n   */\n  experimental_onToolCall?: (\n    toolCallPayload: ToolCallPayload,\n    appendToolCallMessage: (result?: {\n      tool_call_id: string;\n      function_name: string;\n      tool_call_result: JSONValue;\n    }) => CreateMessage[],\n  ) => Promise<\n    Response | undefined | void | string | AsyncIterableOpenAIStreamReturnTypes\n  >;\n};\n\n// https://github.com/openai/openai-node/blob/07b3504e1c40fd929f4aae1651b83afc19e3baf8/src/resources/chat/completions.ts#L28-L40\ninterface ChatCompletionChunk {\n  id: string;\n  choices: Array<ChatCompletionChunkChoice>;\n  created: number;\n  model: string;\n  object: string;\n}\n\n// https://github.com/openai/openai-node/blob/07b3504e1c40fd929f4aae1651b83afc19e3baf8/src/resources/chat/completions.ts#L43-L49\n// Updated for https://github.com/openai/openai-node/commit/f10c757d831d90407ba47b4659d9cd34b1a35b1d\n// Updated to https://github.com/openai/openai-node/commit/84b43280089eacdf18f171723591856811beddce\ninterface ChatCompletionChunkChoice {\n  delta: ChoiceDelta;\n  finish_reason:\n    | 'stop'\n    | 'length'\n    | 'tool_calls'\n    | 'content_filter'\n    | 'function_call'\n    | null;\n  index: number;\n}\n\n// https://github.com/openai/openai-node/blob/07b3504e1c40fd929f4aae1651b83afc19e3baf8/src/resources/chat/completions.ts#L123-L139\n// Updated to https://github.com/openai/openai-node/commit/84b43280089eacdf18f171723591856811beddce\ninterface ChoiceDelta {\n  /**\n   * The contents of the chunk message.\n   */\n  content?: string | null;\n\n  /**\n   * The name and arguments of a function that should be called, as generated by the\n   * model.\n   */\n  function_call?: FunctionCall;\n\n  /**\n   * The role of the author of this message.\n   */\n  role?: 'system' | 'user' | 'assistant' | 'tool';\n\n  tool_calls?: Array<DeltaToolCall>;\n}\n\n// From https://github.com/openai/openai-node/blob/master/src/resources/chat/completions.ts\n// Updated to https://github.com/openai/openai-node/commit/84b43280089eacdf18f171723591856811beddce\ninterface DeltaToolCall {\n  index: number;\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The function that the model called.\n   */\n  function?: ToolCallFunction;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type?: 'function';\n}\n\n// From https://github.com/openai/openai-node/blob/master/src/resources/chat/completions.ts\n// Updated to https://github.com/openai/openai-node/commit/84b43280089eacdf18f171723591856811beddce\ninterface ToolCallFunction {\n  /**\n   * The arguments to call the function with, as generated by the model in JSON\n   * format. Note that the model does not always generate valid JSON, and may\n   * hallucinate parameters not defined by your function schema. Validate the\n   * arguments in your code before calling your function.\n   */\n  arguments?: string;\n\n  /**\n   * The name of the function to call.\n   */\n  name?: string;\n}\n\n/**\n * https://github.com/openai/openai-node/blob/3ec43ee790a2eb6a0ccdd5f25faa23251b0f9b8e/src/resources/completions.ts#L28C1-L64C1\n * Completions API. Streamed and non-streamed responses are the same.\n */\ninterface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\ninterface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, or `length` if the maximum\n   * number of tokens specified in the request was reached.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  // edited: Removed CompletionChoice.logProbs and replaced with any\n  logprobs: any | null;\n\n  text: string;\n}\n\nexport interface CompletionUsage {\n  /**\n   * Usage statistics for the completion request.\n   */\n\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n}\n\n/**\n * Creates a parser function for processing the OpenAI stream data.\n * The parser extracts and trims text content from the JSON data. This parser\n * can handle data for chat or completion models.\n *\n * @return {(data: string) => string | void| { isText: false; content: string }}\n * A parser function that takes a JSON string as input and returns the extracted text content,\n * a complex object with isText: false for function/tool calls, or nothing.\n */\nfunction parseOpenAIStream(): (\n  data: string,\n) => string | void | { isText: false; content: string } {\n  const extract = chunkToText();\n  return data => extract(JSON.parse(data) as OpenAIStreamReturnTypes);\n}\n\n/**\n * Reads chunks from OpenAI's new Streamable interface, which is essentially\n * the same as the old Response body interface with an included SSE parser\n * doing the parsing for us.\n */\nasync function* streamable(stream: AsyncIterableOpenAIStreamReturnTypes) {\n  const extract = chunkToText();\n\n  for await (let chunk of stream) {\n    // convert chunk if it is an Azure chat completion. Azure does not expose all\n    // properties in the interfaces, and also uses camelCase instead of snake_case\n    if ('promptFilterResults' in chunk) {\n      chunk = {\n        id: chunk.id,\n        created: chunk.created.getDate(),\n        object: (chunk as any).object, // not exposed by Azure API\n        model: (chunk as any).model, // not exposed by Azure API\n        choices: chunk.choices.map(choice => ({\n          delta: {\n            content: choice.delta?.content,\n            function_call: choice.delta?.functionCall,\n            role: choice.delta?.role as any,\n            tool_calls: choice.delta?.toolCalls?.length\n              ? choice.delta?.toolCalls?.map((toolCall, index) => ({\n                  index,\n                  id: toolCall.id,\n                  function: toolCall.function,\n                  type: toolCall.type,\n                }))\n              : undefined,\n          },\n          finish_reason: choice.finishReason as any,\n          index: choice.index,\n        })),\n      } satisfies ChatCompletionChunk;\n    }\n\n    const text = extract(chunk);\n\n    if (text) yield text;\n  }\n}\n\nfunction chunkToText(): (\n  chunk: OpenAIStreamReturnTypes,\n) => string | { isText: false; content: string } | void {\n  const trimStartOfStream = trimStartOfStreamHelper();\n  let isFunctionStreamingIn: boolean;\n  return json => {\n    if (isChatCompletionChunk(json)) {\n      const delta = json.choices[0]?.delta;\n      if (delta.function_call?.name) {\n        isFunctionStreamingIn = true;\n        return {\n          isText: false,\n          content: `{\"function_call\": {\"name\": \"${delta.function_call.name}\", \"arguments\": \"`,\n        };\n      } else if (delta.tool_calls?.[0]?.function?.name) {\n        isFunctionStreamingIn = true;\n        const toolCall = delta.tool_calls[0];\n        if (toolCall.index === 0) {\n          return {\n            isText: false,\n            content: `{\"tool_calls\":[ {\"id\": \"${toolCall.id}\", \"type\": \"function\", \"function\": {\"name\": \"${toolCall.function?.name}\", \"arguments\": \"`,\n          };\n        } else {\n          return {\n            isText: false,\n            content: `\"}}, {\"id\": \"${toolCall.id}\", \"type\": \"function\", \"function\": {\"name\": \"${toolCall.function?.name}\", \"arguments\": \"`,\n          };\n        }\n      } else if (delta.function_call?.arguments) {\n        return {\n          isText: false,\n          content: cleanupArguments(delta.function_call?.arguments),\n        };\n      } else if (delta.tool_calls?.[0]?.function?.arguments) {\n        return {\n          isText: false,\n          content: cleanupArguments(delta.tool_calls?.[0]?.function?.arguments),\n        };\n      } else if (\n        isFunctionStreamingIn &&\n        (json.choices[0]?.finish_reason === 'function_call' ||\n          json.choices[0]?.finish_reason === 'stop')\n      ) {\n        isFunctionStreamingIn = false; // Reset the flag\n        return {\n          isText: false,\n          content: '\"}}',\n        };\n      } else if (\n        isFunctionStreamingIn &&\n        json.choices[0]?.finish_reason === 'tool_calls'\n      ) {\n        isFunctionStreamingIn = false; // Reset the flag\n        return {\n          isText: false,\n          content: '\"}}]}',\n        };\n      }\n    }\n\n    const text = trimStartOfStream(\n      isChatCompletionChunk(json) && json.choices[0].delta.content\n        ? json.choices[0].delta.content\n        : isCompletion(json)\n        ? json.choices[0].text\n        : '',\n    );\n\n    return text;\n  };\n\n  function cleanupArguments(argumentChunk: string) {\n    let escapedPartialJson = argumentChunk\n      .replace(/\\\\/g, '\\\\\\\\') // Replace backslashes first to prevent double escaping\n      .replace(/\\//g, '\\\\/') // Escape slashes\n      .replace(/\"/g, '\\\\\"') // Escape double quotes\n      .replace(/\\n/g, '\\\\n') // Escape new lines\n      .replace(/\\r/g, '\\\\r') // Escape carriage returns\n      .replace(/\\t/g, '\\\\t') // Escape tabs\n      .replace(/\\f/g, '\\\\f'); // Escape form feeds\n\n    return `${escapedPartialJson}`;\n  }\n}\n\nconst __internal__OpenAIFnMessagesSymbol = Symbol(\n  'internal_openai_fn_messages',\n);\n\ntype AsyncIterableOpenAIStreamReturnTypes =\n  | AsyncIterable<ChatCompletionChunk>\n  | AsyncIterable<Completion>\n  | AsyncIterable<AzureChatCompletions>;\n\ntype ExtractType<T> = T extends AsyncIterable<infer U> ? U : never;\n\ntype OpenAIStreamReturnTypes =\n  ExtractType<AsyncIterableOpenAIStreamReturnTypes>;\n\nfunction isChatCompletionChunk(\n  data: OpenAIStreamReturnTypes,\n): data is ChatCompletionChunk {\n  return (\n    'choices' in data &&\n    data.choices &&\n    data.choices[0] &&\n    'delta' in data.choices[0]\n  );\n}\n\nfunction isCompletion(data: OpenAIStreamReturnTypes): data is Completion {\n  return (\n    'choices' in data &&\n    data.choices &&\n    data.choices[0] &&\n    'text' in data.choices[0]\n  );\n}\n\nexport function OpenAIStream(\n  res: Response | AsyncIterableOpenAIStreamReturnTypes,\n  callbacks?: OpenAIStreamCallbacks,\n): ReadableStream {\n  // Annotate the internal `messages` property for recursive function calls\n  const cb:\n    | undefined\n    | (OpenAIStreamCallbacks & {\n        [__internal__OpenAIFnMessagesSymbol]?: CreateMessage[];\n      }) = callbacks;\n\n  let stream: ReadableStream<Uint8Array>;\n  if (Symbol.asyncIterator in res) {\n    stream = readableFromAsyncIterable(streamable(res)).pipeThrough(\n      createCallbacksTransformer(\n        cb?.experimental_onFunctionCall || cb?.experimental_onToolCall\n          ? {\n              ...cb,\n              onFinal: undefined,\n            }\n          : {\n              ...cb,\n            },\n      ),\n    );\n  } else {\n    stream = AIStream(\n      res,\n      parseOpenAIStream(),\n      cb?.experimental_onFunctionCall || cb?.experimental_onToolCall\n        ? {\n            ...cb,\n            onFinal: undefined,\n          }\n        : {\n            ...cb,\n          },\n    );\n  }\n\n  if (cb && (cb.experimental_onFunctionCall || cb.experimental_onToolCall)) {\n    const functionCallTransformer = createFunctionCallTransformer(cb);\n    return stream.pipeThrough(functionCallTransformer);\n  } else {\n    return stream.pipeThrough(\n      createStreamDataTransformer(cb?.experimental_streamData),\n    );\n  }\n}\n\nfunction createFunctionCallTransformer(\n  callbacks: OpenAIStreamCallbacks & {\n    [__internal__OpenAIFnMessagesSymbol]?: CreateMessage[];\n  },\n): TransformStream<Uint8Array, Uint8Array> {\n  const textEncoder = new TextEncoder();\n  let isFirstChunk = true;\n  let aggregatedResponse = '';\n  let aggregatedFinalCompletionResponse = '';\n  let isFunctionStreamingIn = false;\n\n  let functionCallMessages: CreateMessage[] =\n    callbacks[__internal__OpenAIFnMessagesSymbol] || [];\n\n  const isComplexMode = callbacks?.experimental_streamData;\n  const decode = createChunkDecoder();\n\n  return new TransformStream({\n    async transform(chunk, controller): Promise<void> {\n      const message = decode(chunk);\n      aggregatedFinalCompletionResponse += message;\n\n      const shouldHandleAsFunction =\n        isFirstChunk &&\n        (message.startsWith('{\"function_call\":') ||\n          message.startsWith('{\"tool_calls\":'));\n\n      if (shouldHandleAsFunction) {\n        isFunctionStreamingIn = true;\n        aggregatedResponse += message;\n        isFirstChunk = false;\n        return;\n      }\n\n      // Stream as normal\n      if (!isFunctionStreamingIn) {\n        controller.enqueue(\n          isComplexMode\n            ? textEncoder.encode(formatStreamPart('text', message))\n            : chunk,\n        );\n        return;\n      } else {\n        aggregatedResponse += message;\n      }\n    },\n    async flush(controller): Promise<void> {\n      try {\n        if (\n          !isFirstChunk &&\n          isFunctionStreamingIn &&\n          (callbacks.experimental_onFunctionCall ||\n            callbacks.experimental_onToolCall)\n        ) {\n          isFunctionStreamingIn = false;\n          const payload = JSON.parse(aggregatedResponse);\n          // Append the function call message to the list\n          let newFunctionCallMessages: CreateMessage[] = [\n            ...functionCallMessages,\n          ];\n\n          let functionResponse:\n            | Response\n            | undefined\n            | void\n            | string\n            | AsyncIterableOpenAIStreamReturnTypes\n            | undefined = undefined;\n          // This callbacks.experimental_onFunctionCall check should not be necessary but TS complains\n          if (callbacks.experimental_onFunctionCall) {\n            // If the user is using the experimental_onFunctionCall callback, they should not be using tools\n            // if payload.function_call is not defined by time we get here we must have gotten a tool response\n            // and the user had defined experimental_onToolCall\n            if (payload.function_call === undefined) {\n              console.warn(\n                'experimental_onFunctionCall should not be defined when using tools',\n              );\n            }\n\n            const argumentsPayload = JSON.parse(\n              payload.function_call.arguments,\n            );\n\n            functionResponse = await callbacks.experimental_onFunctionCall(\n              {\n                name: payload.function_call.name,\n                arguments: argumentsPayload,\n              },\n              result => {\n                // Append the function call request and result messages to the list\n                newFunctionCallMessages = [\n                  ...functionCallMessages,\n                  {\n                    role: 'assistant',\n                    content: '',\n                    function_call: payload.function_call,\n                  },\n                  {\n                    role: 'function',\n                    name: payload.function_call.name,\n                    content: JSON.stringify(result),\n                  },\n                ];\n                // Return it to the user\n                return newFunctionCallMessages;\n              },\n            );\n          }\n          if (callbacks.experimental_onToolCall) {\n            const toolCalls: ToolCallPayload = {\n              tools: [],\n            };\n            for (const tool of payload.tool_calls) {\n              toolCalls.tools.push({\n                id: tool.id,\n                type: 'function',\n                func: {\n                  name: tool.function.name,\n                  arguments: JSON.parse(tool.function.arguments),\n                },\n              });\n            }\n            let responseIndex = 0;\n            try {\n              functionResponse = await callbacks.experimental_onToolCall(\n                toolCalls,\n                result => {\n                  if (result) {\n                    const { tool_call_id, function_name, tool_call_result } =\n                      result;\n                    // Append the function call request and result messages to the list\n                    newFunctionCallMessages = [\n                      ...newFunctionCallMessages,\n                      // Only append the assistant message if it's the first response\n                      ...(responseIndex === 0\n                        ? [\n                            {\n                              role: 'assistant' as const,\n                              content: '',\n                              tool_calls: payload.tool_calls.map(\n                                (tc: ToolCall) => ({\n                                  id: tc.id,\n                                  type: 'function',\n                                  function: {\n                                    name: tc.function.name,\n                                    // we send the arguments an object to the user, but as the API expects a string, we need to stringify it\n                                    arguments: JSON.stringify(\n                                      tc.function.arguments,\n                                    ),\n                                  },\n                                }),\n                              ),\n                            },\n                          ]\n                        : []),\n                      // Append the function call result message\n                      {\n                        role: 'tool',\n                        tool_call_id,\n                        name: function_name,\n                        content: JSON.stringify(tool_call_result),\n                      },\n                    ];\n                    responseIndex++;\n                  }\n                  // Return it to the user\n                  return newFunctionCallMessages;\n                },\n              );\n            } catch (e) {\n              console.error('Error calling experimental_onToolCall:', e);\n            }\n          }\n\n          if (!functionResponse) {\n            // The user didn't do anything with the function call on the server and wants\n            // to either do nothing or run it on the client\n            // so we just return the function call as a message\n            controller.enqueue(\n              textEncoder.encode(\n                isComplexMode\n                  ? formatStreamPart(\n                      payload.function_call ? 'function_call' : 'tool_calls',\n                      // parse to prevent double-encoding:\n                      JSON.parse(aggregatedResponse),\n                    )\n                  : aggregatedResponse,\n              ),\n            );\n            return;\n          } else if (typeof functionResponse === 'string') {\n            // The user returned a string, so we just return it as a message\n            controller.enqueue(\n              isComplexMode\n                ? textEncoder.encode(formatStreamPart('text', functionResponse))\n                : textEncoder.encode(functionResponse),\n            );\n            aggregatedFinalCompletionResponse = functionResponse;\n            return;\n          }\n\n          // Recursively:\n\n          // We don't want to trigger onStart or onComplete recursively\n          // so we remove them from the callbacks\n          // see https://github.com/vercel/ai/issues/351\n          const filteredCallbacks: OpenAIStreamCallbacks = {\n            ...callbacks,\n            onStart: undefined,\n          };\n          // We only want onFinal to be called the _last_ time\n          callbacks.onFinal = undefined;\n\n          const openAIStream = OpenAIStream(functionResponse, {\n            ...filteredCallbacks,\n            [__internal__OpenAIFnMessagesSymbol]: newFunctionCallMessages,\n          } as AIStreamCallbacksAndOptions);\n\n          const reader = openAIStream.getReader();\n\n          while (true) {\n            const { done, value } = await reader.read();\n            if (done) {\n              break;\n            }\n            controller.enqueue(value);\n          }\n        }\n      } finally {\n        if (callbacks.onFinal && aggregatedFinalCompletionResponse) {\n          await callbacks.onFinal(aggregatedFinalCompletionResponse);\n        }\n      }\n    },\n  });\n}\n","import { AIStream, type AIStreamCallbacksAndOptions } from './ai-stream';\nimport { createStreamDataTransformer } from './stream-data';\n\n// from replicate SDK\ninterface Prediction {\n  id: string;\n  status: 'starting' | 'processing' | 'succeeded' | 'failed' | 'canceled';\n  version: string;\n  input: object;\n  output?: any;\n  source: 'api' | 'web';\n  error?: any;\n  logs?: string;\n  metrics?: {\n    predict_time?: number;\n  };\n  webhook?: string;\n  webhook_events_filter?: ('start' | 'output' | 'logs' | 'completed')[];\n  created_at: string;\n  updated_at?: string;\n  completed_at?: string;\n  urls: {\n    get: string;\n    cancel: string;\n    stream?: string;\n  };\n}\n\n/**\n * Stream predictions from Replicate.\n * Only certain models are supported and you must pass `stream: true` to\n * replicate.predictions.create().\n * @see https://github.com/replicate/replicate-javascript#streaming\n *\n * @example\n * const response = await replicate.predictions.create({\n *  stream: true,\n *  input: {\n *    prompt: messages.join('\\n')\n *  },\n *  version: '2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1'\n * })\n *\n * const stream = await ReplicateStream(response)\n * return new StreamingTextResponse(stream)\n *\n */\nexport async function ReplicateStream(\n  res: Prediction,\n  cb?: AIStreamCallbacksAndOptions,\n  options?: {\n    headers?: Record<string, string>;\n  },\n): Promise<ReadableStream> {\n  const url = res.urls?.stream;\n\n  if (!url) {\n    if (res.error) throw new Error(res.error);\n    else throw new Error('Missing stream URL in Replicate response');\n  }\n\n  const eventStream = await fetch(url, {\n    method: 'GET',\n    headers: {\n      Accept: 'text/event-stream',\n      ...options?.headers,\n    },\n  });\n\n  return AIStream(eventStream, undefined, cb).pipeThrough(\n    createStreamDataTransformer(cb?.experimental_streamData),\n  );\n}\n","import { StreamPartType, parseStreamPart } from './stream-parts';\n\nconst NEWLINE = '\\n'.charCodeAt(0);\n\n// concatenates all the chunks into a single Uint8Array\nfunction concatChunks(chunks: Uint8Array[], totalLength: number) {\n  const concatenatedChunks = new Uint8Array(totalLength);\n\n  let offset = 0;\n  for (const chunk of chunks) {\n    concatenatedChunks.set(chunk, offset);\n    offset += chunk.length;\n  }\n  chunks.length = 0;\n\n  return concatenatedChunks;\n}\n\nexport async function* readDataStream(\n  reader: ReadableStreamDefaultReader<Uint8Array>,\n  {\n    isAborted,\n  }: {\n    isAborted?: () => boolean;\n  } = {},\n): AsyncGenerator<StreamPartType> {\n  // implementation note: this slightly more complex algorithm is required\n  // to pass the tests in the edge environment.\n\n  const decoder = new TextDecoder();\n  const chunks: Uint8Array[] = [];\n  let totalLength = 0;\n\n  while (true) {\n    const { value } = await reader.read();\n\n    if (value) {\n      chunks.push(value);\n      totalLength += value.length;\n      if (value[value.length - 1] !== NEWLINE) {\n        // if the last character is not a newline, we have not read the whole JSON value\n        continue;\n      }\n    }\n\n    if (chunks.length === 0) {\n      break; // we have reached the end of the stream\n    }\n\n    const concatenatedChunks = concatChunks(chunks, totalLength);\n    totalLength = 0;\n\n    const streamParts = decoder\n      .decode(concatenatedChunks, { stream: true })\n      .split('\\n')\n      .filter(line => line !== '') // splitting leaves an empty string at the end\n      .map(parseStreamPart);\n\n    for (const streamPart of streamParts) {\n      yield streamPart;\n    }\n\n    // The request has been aborted, stop reading the stream.\n    if (isAborted?.()) {\n      reader.cancel();\n      break;\n    }\n  }\n}\n","import { readDataStream } from './read-data-stream';\nimport type { FunctionCall, JSONValue, Message, ToolCall } from './types';\nimport { nanoid } from './utils';\n\ntype PrefixMap = {\n  text?: Message;\n  function_call?: Message & {\n    role: 'assistant';\n    function_call: FunctionCall;\n  };\n  tool_calls?: Message & {\n    role: 'assistant';\n    tool_calls: ToolCall[];\n  };\n  data: JSONValue[];\n};\n\nfunction assignAnnotationsToMessage<T extends Message | null | undefined>(\n  message: T,\n  annotations: JSONValue[] | undefined,\n): T {\n  if (!message || !annotations || !annotations.length) return message;\n  return { ...message, annotations: [...annotations] } as T;\n}\n\nexport async function parseComplexResponse({\n  reader,\n  abortControllerRef,\n  update,\n  onFinish,\n  generateId = nanoid,\n  getCurrentDate = () => new Date(),\n}: {\n  reader: ReadableStreamDefaultReader<Uint8Array>;\n  abortControllerRef?: {\n    current: AbortController | null;\n  };\n  update: (merged: Message[], data: JSONValue[] | undefined) => void;\n  onFinish?: (prefixMap: PrefixMap) => void;\n  generateId?: () => string;\n  getCurrentDate?: () => Date;\n}) {\n  const createdAt = getCurrentDate();\n  const prefixMap: PrefixMap = {\n    data: [],\n  };\n\n  // keep list of current message annotations for message\n  let message_annotations: JSONValue[] | undefined = undefined;\n\n  // we create a map of each prefix, and for each prefixed message we push to the map\n  for await (const { type, value } of readDataStream(reader, {\n    isAborted: () => abortControllerRef?.current === null,\n  })) {\n    if (type === 'text') {\n      if (prefixMap['text']) {\n        prefixMap['text'] = {\n          ...prefixMap['text'],\n          content: (prefixMap['text'].content || '') + value,\n        };\n      } else {\n        prefixMap['text'] = {\n          id: generateId(),\n          role: 'assistant',\n          content: value,\n          createdAt,\n        };\n      }\n    }\n\n    let functionCallMessage: Message | null | undefined = null;\n\n    if (type === 'function_call') {\n      prefixMap['function_call'] = {\n        id: generateId(),\n        role: 'assistant',\n        content: '',\n        function_call: value.function_call,\n        name: value.function_call.name,\n        createdAt,\n      };\n\n      functionCallMessage = prefixMap['function_call'];\n    }\n\n    let toolCallMessage: Message | null | undefined = null;\n\n    if (type === 'tool_calls') {\n      prefixMap['tool_calls'] = {\n        id: generateId(),\n        role: 'assistant',\n        content: '',\n        tool_calls: value.tool_calls,\n        createdAt,\n      };\n\n      toolCallMessage = prefixMap['tool_calls'];\n    }\n\n    if (type === 'data') {\n      prefixMap['data'].push(...value);\n    }\n\n    let responseMessage = prefixMap['text'];\n\n    if (type === 'message_annotations') {\n      if (!message_annotations) {\n        message_annotations = [...value];\n      } else {\n        message_annotations.push(...value);\n      }\n\n      // Update any existing message with the latest annotations\n      functionCallMessage = assignAnnotationsToMessage(\n        prefixMap['function_call'],\n        message_annotations,\n      );\n      toolCallMessage = assignAnnotationsToMessage(\n        prefixMap['tool_calls'],\n        message_annotations,\n      );\n      responseMessage = assignAnnotationsToMessage(\n        prefixMap['text'],\n        message_annotations,\n      );\n    }\n\n    // keeps the prefixMap up to date with the latest annotations, even if annotations preceded the message\n    if (message_annotations?.length) {\n      const messagePrefixKeys: (keyof PrefixMap)[] = [\n        'text',\n        'function_call',\n        'tool_calls',\n      ];\n      messagePrefixKeys.forEach(key => {\n        if (prefixMap[key]) {\n          (prefixMap[key] as Message).annotations = [...message_annotations!];\n        }\n      });\n    }\n\n    // We add function & tool calls and response messages to the messages[], but data is its own thing\n    const merged = [functionCallMessage, toolCallMessage, responseMessage]\n      .filter(Boolean)\n      .map(message => ({\n        ...assignAnnotationsToMessage(message, message_annotations),\n      })) as Message[];\n\n    update(merged, [...prefixMap['data']]); // make a copy of the data array\n  }\n\n  onFinish?.(prefixMap);\n\n  return {\n    messages: [\n      prefixMap.text,\n      prefixMap.function_call,\n      prefixMap.tool_calls,\n    ].filter(Boolean) as Message[],\n    data: prefixMap.data,\n  };\n}\n","/**\n * This is a naive implementation of the streaming React response API.\n * Currently, it can carry the original raw content, data payload and a special\n * UI payload and stream them via \"rows\" (nested promises).\n * It must be used inside Server Actions so Flight can encode the React elements.\n *\n * It is naive as unlike the StreamingTextResponse, it does not send the diff\n * between the rows, but flushing the full payload on each row.\n */\n\nimport { parseComplexResponse } from '../shared/parse-complex-response';\nimport { IdGenerator, JSONValue } from '../shared/types';\nimport { createChunkDecoder, nanoid } from '../shared/utils';\nimport { experimental_StreamData } from './stream-data';\n\ntype UINode = string | JSX.Element | JSX.Element[] | null | undefined;\n\ntype Payload = {\n  ui: UINode | Promise<UINode>;\n  content: string;\n};\n\nexport type ReactResponseRow = Payload & {\n  next: null | Promise<ReactResponseRow>;\n};\n\n/**\n * A utility class for streaming React responses.\n */\nexport class experimental_StreamingReactResponse {\n  constructor(\n    res: ReadableStream,\n    options?: {\n      ui?: (message: {\n        content: string;\n        data?: JSONValue[] | undefined;\n      }) => UINode | Promise<UINode>;\n      data?: experimental_StreamData;\n      generateId?: IdGenerator;\n    },\n  ) {\n    let resolveFunc: (row: ReactResponseRow) => void = () => {};\n    let next = new Promise<ReactResponseRow>(resolve => {\n      resolveFunc = resolve;\n    });\n\n    if (options?.data) {\n      const processedStream: ReadableStream<Uint8Array> = res.pipeThrough(\n        options.data.stream,\n      );\n\n      let lastPayload: Payload | undefined = undefined;\n\n      // runs asynchronously (no await on purpose)\n      parseComplexResponse({\n        reader: processedStream.getReader(),\n        update: (merged, data) => {\n          const content = merged[0]?.content ?? '';\n          const ui = options?.ui?.({ content, data }) || content;\n          const payload: Payload = { ui, content };\n\n          const resolvePrevious = resolveFunc;\n          const nextRow = new Promise<ReactResponseRow>(resolve => {\n            resolveFunc = resolve;\n          });\n\n          resolvePrevious({\n            next: nextRow,\n            ...payload,\n          });\n\n          lastPayload = payload;\n        },\n        generateId: options.generateId ?? nanoid,\n        onFinish: () => {\n          // The last payload is resolved twice. This is necessary because we immediately\n          // push out a payload, but we also need to forward the finish event with a payload.\n          if (lastPayload !== undefined) {\n            resolveFunc({\n              next: null,\n              ...lastPayload,\n            });\n          }\n        },\n      });\n\n      return next;\n    }\n\n    let content = '';\n\n    const decode = createChunkDecoder();\n    const reader = res.getReader();\n    async function readChunk() {\n      const { done, value } = await reader.read();\n      if (!done) {\n        content += decode(value);\n      }\n\n      // TODO: Handle generators. With this current implementation we can support\n      // synchronous and asynchronous UIs.\n      // TODO: Handle function calls.\n      const ui = options?.ui?.({ content }) || content;\n\n      const payload: Payload = {\n        ui,\n        content,\n      };\n\n      const resolvePrevious = resolveFunc;\n      const nextRow = done\n        ? null\n        : new Promise<ReactResponseRow>(resolve => {\n            resolveFunc = resolve;\n          });\n      resolvePrevious({\n        next: nextRow,\n        ...payload,\n      });\n\n      if (done) {\n        return;\n      }\n\n      await readChunk();\n    }\n    readChunk();\n\n    return next;\n  }\n}\n","import type { ServerResponse } from 'node:http';\nimport { experimental_StreamData } from './stream-data';\nimport { COMPLEX_HEADER } from '../shared/utils';\n\n/**\n * A utility class for streaming text responses.\n */\nexport class StreamingTextResponse extends Response {\n  constructor(\n    res: ReadableStream,\n    init?: ResponseInit,\n    data?: experimental_StreamData,\n  ) {\n    let processedStream = res;\n\n    if (data) {\n      processedStream = res.pipeThrough(data.stream);\n    }\n\n    super(processedStream as any, {\n      ...init,\n      status: 200,\n      headers: {\n        'Content-Type': 'text/plain; charset=utf-8',\n        [COMPLEX_HEADER]: data ? 'true' : 'false',\n        ...init?.headers,\n      },\n    });\n  }\n}\n\n/**\n * A utility function to stream a ReadableStream to a Node.js response-like object.\n */\nexport function streamToResponse(\n  res: ReadableStream,\n  response: ServerResponse,\n  init?: { headers?: Record<string, string>; status?: number },\n) {\n  response.writeHead(init?.status || 200, {\n    'Content-Type': 'text/plain; charset=utf-8',\n    ...init?.headers,\n  });\n\n  const reader = res.getReader();\n  function read() {\n    reader.read().then(({ done, value }: { done: boolean; value?: any }) => {\n      if (done) {\n        response.end();\n        return;\n      }\n      response.write(value);\n      read();\n    });\n  }\n  read();\n}\n"],"mappings":";AAAA,SAAS,sBAAsB;;;ACe/B,IAAM,iBAAkD;AAAA,EACtD,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QAAI,OAAO,UAAU,UAAU;AAC7B,YAAM,IAAI,MAAM,qCAAqC;AAAA,IACvD;AACA,WAAO,EAAE,MAAM,QAAQ,MAAM;AAAA,EAC/B;AACF;AAEA,IAAM,yBAIF;AAAA,EACF,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QACE,SAAS,QACT,OAAO,UAAU,YACjB,EAAE,mBAAmB,UACrB,OAAO,MAAM,kBAAkB,YAC/B,MAAM,iBAAiB,QACvB,EAAE,UAAU,MAAM,kBAClB,EAAE,eAAe,MAAM,kBACvB,OAAO,MAAM,cAAc,SAAS,YACpC,OAAO,MAAM,cAAc,cAAc,UACzC;AACA,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAM,iBAA4D;AAAA,EAChE,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACzB,YAAM,IAAI,MAAM,qCAAqC;AAAA,IACvD;AAEA,WAAO,EAAE,MAAM,QAAQ,MAAM;AAAA,EAC/B;AACF;AAEA,IAAM,kBAAoD;AAAA,EACxD,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QAAI,OAAO,UAAU,UAAU;AAC7B,YAAM,IAAI,MAAM,sCAAsC;AAAA,IACxD;AACA,WAAO,EAAE,MAAM,SAAS,MAAM;AAAA,EAChC;AACF;AAEA,IAAM,6BAIF;AAAA,EACF,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QACE,SAAS,QACT,OAAO,UAAU,YACjB,EAAE,QAAQ,UACV,EAAE,UAAU,UACZ,EAAE,aAAa,UACf,OAAO,MAAM,OAAO,YACpB,OAAO,MAAM,SAAS,YACtB,MAAM,SAAS,eACf,CAAC,MAAM,QAAQ,MAAM,OAAO,KAC5B,CAAC,MAAM,QAAQ;AAAA,MACb,UACE,QAAQ,QACR,OAAO,SAAS,YAChB,UAAU,QACV,KAAK,SAAS,UACd,UAAU,QACV,KAAK,QAAQ,QACb,OAAO,KAAK,SAAS,YACrB,WAAW,KAAK,QAChB,OAAO,KAAK,KAAK,UAAU;AAAA,IAC/B,GACA;AACA,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAM,iCAOF;AAAA,EACF,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QACE,SAAS,QACT,OAAO,UAAU,YACjB,EAAE,cAAc,UAChB,EAAE,eAAe,UACjB,OAAO,MAAM,aAAa,YAC1B,OAAO,MAAM,cAAc,UAC3B;AACA,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,QACL,UAAU,MAAM;AAAA,QAChB,WAAW,MAAM;AAAA,MACnB;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAM,wBAAsE;AAAA,EAC1E,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QACE,SAAS,QACT,OAAO,UAAU,YACjB,EAAE,UAAU,UACZ,EAAE,UAAU,UACZ,OAAO,MAAM,SAAS,YACtB,MAAM,SAAS,QACf;AACA,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAM,qBAIF;AAAA,EACF,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QACE,SAAS,QACT,OAAO,UAAU,YACjB,EAAE,gBAAgB,UAClB,OAAO,MAAM,eAAe,YAC5B,MAAM,cAAc,QACpB,CAAC,MAAM,QAAQ,MAAM,UAAU,KAC/B,MAAM,WAAW,KAAK,QAAM;AAC1B,YAAM,QACJ,OAAO,OAAO,YACd,EAAE,QAAQ,OACV,OAAO,GAAG,OAAO,YACjB,EAAE,UAAU,OACZ,OAAO,GAAG,SAAS,YACnB,EAAE,cAAc,OAChB,GAAG,YAAY,QACf,OAAO,GAAG,aAAa,YACvB,EAAE,eAAe,GAAG,aACpB,OAAO,GAAG,SAAS,SAAS,YAC5B,OAAO,GAAG,SAAS,cAAc;AAAA,IACrC,CAAC,GACD;AACA,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAM,+BAIF;AAAA,EACF,MAAM;AAAA,EACN,MAAM;AAAA,EACN,OAAO,CAAC,UAAqB;AAC3B,QAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACzB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,WAAO,EAAE,MAAM,uBAAuB,MAAM;AAAA,EAC9C;AACF;AAEA,IAAM,cAAc;AAAA,EAClB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AA+BO,IAAM,oBAAoB;AAAA,EAC/B,CAAC,eAAe,IAAI,GAAG;AAAA,EACvB,CAAC,uBAAuB,IAAI,GAAG;AAAA,EAC/B,CAAC,eAAe,IAAI,GAAG;AAAA,EACvB,CAAC,gBAAgB,IAAI,GAAG;AAAA,EACxB,CAAC,2BAA2B,IAAI,GAAG;AAAA,EACnC,CAAC,+BAA+B,IAAI,GAAG;AAAA,EACvC,CAAC,sBAAsB,IAAI,GAAG;AAAA,EAC9B,CAAC,mBAAmB,IAAI,GAAG;AAAA,EAC3B,CAAC,6BAA6B,IAAI,GAAG;AACvC;AAwBO,IAAM,uBAAuB;AAAA,EAClC,CAAC,eAAe,IAAI,GAAG,eAAe;AAAA,EACtC,CAAC,uBAAuB,IAAI,GAAG,uBAAuB;AAAA,EACtD,CAAC,eAAe,IAAI,GAAG,eAAe;AAAA,EACtC,CAAC,gBAAgB,IAAI,GAAG,gBAAgB;AAAA,EACxC,CAAC,2BAA2B,IAAI,GAAG,2BAA2B;AAAA,EAC9D,CAAC,+BAA+B,IAAI,GAAG,+BAA+B;AAAA,EACtE,CAAC,sBAAsB,IAAI,GAAG,sBAAsB;AAAA,EACpD,CAAC,mBAAmB,IAAI,GAAG,mBAAmB;AAAA,EAC9C,CAAC,6BAA6B,IAAI,GAAG,6BAA6B;AACpE;AAEO,IAAM,aAAa,YAAY,IAAI,UAAQ,KAAK,IAAI;AASpD,IAAM,kBAAkB,CAAC,SAAiC;AAC/D,QAAM,sBAAsB,KAAK,QAAQ,GAAG;AAE5C,MAAI,wBAAwB,IAAI;AAC9B,UAAM,IAAI,MAAM,oDAAoD;AAAA,EACtE;AAEA,QAAM,SAAS,KAAK,MAAM,GAAG,mBAAmB;AAEhD,MAAI,CAAC,WAAW,SAAS,MAAwC,GAAG;AAClE,UAAM,IAAI,MAAM,+CAA+C,MAAM,GAAG;AAAA,EAC1E;AAEA,QAAM,OAAO;AAEb,QAAM,YAAY,KAAK,MAAM,sBAAsB,CAAC;AACpD,QAAM,YAAuB,KAAK,MAAM,SAAS;AAEjD,SAAO,kBAAkB,IAAI,EAAE,MAAM,SAAS;AAChD;AAQO,SAAS,iBACd,MACA,OACc;AACd,QAAM,aAAa,YAAY,KAAK,UAAQ,KAAK,SAAS,IAAI;AAE9D,MAAI,CAAC,YAAY;AACf,UAAM,IAAI,MAAM,6BAA6B,IAAI,EAAE;AAAA,EACrD;AAEA,SAAO,GAAG,WAAW,IAAI,IAAI,KAAK,UAAU,KAAK,CAAC;AAAA;AACpD;;;AD7WO,IAAM,SAAS;AAAA,EACpB;AAAA,EACA;AACF;AAeA,SAAS,mBAAmB,SAAmB;AAC7C,QAAM,UAAU,IAAI,YAAY;AAEhC,MAAI,CAAC,SAAS;AACZ,WAAO,SAAU,OAAuC;AACtD,UAAI,CAAC;AAAO,eAAO;AACnB,aAAO,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAAA,IAC/C;AAAA,EACF;AAEA,SAAO,SAAU,OAA+B;AAC9C,UAAM,UAAU,QACb,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC,EAC9B,MAAM,IAAI,EACV,OAAO,UAAQ,SAAS,EAAE;AAE7B,WAAO,QAAQ,IAAI,eAAe,EAAE,OAAO,OAAO;AAAA,EACpD;AACF;AAIO,IAAM,4BAA4B,CACvC,MACA,UAEA,MAAM,WAAW,GAAG,qBAAqB,IAAI,CAAC,GAAG,KAAK,MAAM,SAAS,IAAI;AAQpE,IAAM,iBAAiB;;;AE5D9B;AAAA,EACE;AAAA,OAIK;AAsEA,SAAS,6BACd,cAC0E;AAC1E,QAAM,cAAc,IAAI,YAAY;AACpC,MAAI;AAEJ,SAAO,IAAI,gBAAgB;AAAA,IACzB,MAAM,MAAM,YAA2B;AACrC,0BAAoB;AAAA,QAClB,CAAC,UAA2C;AAC1C,cACG,UAAU,SACT,MAAM,SAAS,WACf,MAAM,SAAS;AAAA;AAAA,UAGhB,MAAc,UAAU,QACzB;AACA,uBAAW,UAAU;AACrB;AAAA,UACF;AAEA,cAAI,UAAU,OAAO;AACnB,kBAAM,gBAAgB,eAClB,aAAa,MAAM,MAAM;AAAA,cACvB,OAAO,MAAM;AAAA,YACf,CAAC,IACD,MAAM;AACV,gBAAI;AAAe,yBAAW,QAAQ,aAAa;AAAA,UACrD;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,IAEA,UAAU,OAAO;AACf,wBAAkB,KAAK,YAAY,OAAO,KAAK,CAAC;AAAA,IAClD;AAAA,EACF,CAAC;AACH;AAwBO,SAAS,2BACd,IAC0E;AAC1E,QAAM,cAAc,IAAI,YAAY;AACpC,MAAI,qBAAqB;AACzB,QAAM,YAAY,MAAM,CAAC;AAEzB,SAAO,IAAI,gBAAgB;AAAA,IACzB,MAAM,QAAuB;AAC3B,UAAI,UAAU;AAAS,cAAM,UAAU,QAAQ;AAAA,IACjD;AAAA,IAEA,MAAM,UAAU,SAAS,YAA2B;AAClD,YAAM,UAAU,OAAO,YAAY,WAAW,UAAU,QAAQ;AAEhE,iBAAW,QAAQ,YAAY,OAAO,OAAO,CAAC;AAE9C,4BAAsB;AAEtB,UAAI,UAAU;AAAS,cAAM,UAAU,QAAQ,OAAO;AACtD,UAAI,UAAU,UAAU,OAAO,YAAY,UAAU;AACnD,cAAM,UAAU,OAAO,OAAO;AAAA,MAChC;AAAA,IACF;AAAA,IAEA,MAAM,QAAuB;AAC3B,YAAM,oBAAoB,8BAA8B,SAAS;AAGjE,UAAI,UAAU,cAAc;AAC1B,cAAM,UAAU,aAAa,kBAAkB;AAAA,MACjD;AAEA,UAAI,UAAU,WAAW,CAAC,mBAAmB;AAC3C,cAAM,UAAU,QAAQ,kBAAkB;AAAA,MAC5C;AAAA,IACF;AAAA,EACF,CAAC;AACH;AAEA,SAAS,8BACP,WACoC;AACpC,SAAO,iCAAiC;AAC1C;AAgBO,SAAS,0BAAoD;AAClE,MAAI,gBAAgB;AAEpB,SAAO,CAAC,SAAyB;AAC/B,QAAI,eAAe;AACjB,aAAO,KAAK,UAAU;AACtB,UAAI;AAAM,wBAAgB;AAAA,IAC5B;AACA,WAAO;AAAA,EACT;AACF;AAoBO,SAAS,SACd,UACA,cACA,WAC4B;AAC5B,MAAI,CAAC,SAAS,IAAI;AAChB,QAAI,SAAS,MAAM;AACjB,YAAM,SAAS,SAAS,KAAK,UAAU;AACvC,aAAO,IAAI,eAAe;AAAA,QACxB,MAAM,MAAM,YAAY;AACtB,gBAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,cAAI,CAAC,MAAM;AACT,kBAAM,YAAY,IAAI,YAAY,EAAE,OAAO,KAAK;AAChD,uBAAW,MAAM,IAAI,MAAM,mBAAmB,SAAS,EAAE,CAAC;AAAA,UAC5D;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,OAAO;AACL,aAAO,IAAI,eAAe;AAAA,QACxB,MAAM,YAAY;AAChB,qBAAW,MAAM,IAAI,MAAM,kCAAkC,CAAC;AAAA,QAChE;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AAEA,QAAM,qBAAqB,SAAS,QAAQ,0BAA0B;AAEtE,SAAO,mBACJ,YAAY,6BAA6B,YAAY,CAAC,EACtD,YAAY,2BAA2B,SAAS,CAAC;AACtD;AAeA,SAAS,4BAA4C;AACnD,SAAO,IAAI,eAAe;AAAA,IACxB,MAAM,YAAY;AAChB,iBAAW,MAAM;AAAA,IACnB;AAAA,EACF,CAAC;AACH;AAMO,SAAS,0BAA6B,UAA4B;AACvE,MAAI,KAAK,SAAS,OAAO,aAAa,EAAE;AACxC,SAAO,IAAI,eAAkB;AAAA,IAC3B,MAAM,KAAK,YAAY;AACrB,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,GAAG,KAAK;AACtC,UAAI;AAAM,mBAAW,MAAM;AAAA;AACtB,mBAAW,QAAQ,KAAK;AAAA,IAC/B;AAAA,IAEA,MAAM,OAAO,QAAQ;AAtSzB;AAuSM,cAAM,QAAG,WAAH,4BAAY;AAAA,IACpB;AAAA,EACF,CAAC;AACH;;;ACpSO,IAAM,0BAAN,MAA8B;AAAA,EAiBnC,cAAc;AAhBd,SAAQ,UAAU,IAAI,YAAY;AAElC,SAAQ,aACN;AAKF;AAAA;AAAA,SAAQ,kBAAwC;AAChD,SAAQ,0BAAoD;AAC5D,SAAQ,WAAoB;AAG5B;AAAA,SAAQ,OAAoB,CAAC;AAC7B,SAAQ,qBAAkC,CAAC;AAGzC,SAAK,kBAAkB,IAAI,QAAQ,aAAW;AAC5C,WAAK,0BAA0B;AAAA,IACjC,CAAC;AAED,UAAM,OAAO;AACb,SAAK,SAAS,IAAI,gBAAgB;AAAA,MAChC,OAAO,OAAM,eAAc;AACzB,aAAK,aAAa;AAAA,MACpB;AAAA,MACA,WAAW,OAAO,OAAO,eAAe;AAEtC,YAAI,KAAK,KAAK,SAAS,GAAG;AACxB,gBAAM,cAAc,KAAK,QAAQ;AAAA,YAC/B,iBAAiB,QAAQ,KAAK,IAAI;AAAA,UACpC;AACA,eAAK,OAAO,CAAC;AACb,qBAAW,QAAQ,WAAW;AAAA,QAChC;AAEA,YAAI,KAAK,mBAAmB,QAAQ;AAClC,gBAAM,4BAA4B,KAAK,QAAQ;AAAA,YAC7C,iBAAiB,uBAAuB,KAAK,kBAAkB;AAAA,UACjE;AACA,eAAK,qBAAqB,CAAC;AAC3B,qBAAW,QAAQ,yBAAyB;AAAA,QAC9C;AAEA,mBAAW,QAAQ,KAAK;AAAA,MAC1B;AAAA,MACA,MAAM,MAAM,YAAY;AAEtB,cAAM,iBACJ,QAAQ,IAAI,aAAa,gBACrB,WAAW,MAAM;AACf,kBAAQ;AAAA,YACN;AAAA,UACF;AAAA,QACF,GAAG,GAAI,IACP;AAEN,cAAM,KAAK;AAEX,YAAI,mBAAmB,MAAM;AAC3B,uBAAa,cAAc;AAAA,QAC7B;AAEA,YAAI,KAAK,KAAK,QAAQ;AACpB,gBAAM,cAAc,KAAK,QAAQ;AAAA,YAC/B,iBAAiB,QAAQ,KAAK,IAAI;AAAA,UACpC;AACA,qBAAW,QAAQ,WAAW;AAAA,QAChC;AAEA,YAAI,KAAK,mBAAmB,QAAQ;AAClC,gBAAM,cAAc,KAAK,QAAQ;AAAA,YAC/B,iBAAiB,uBAAuB,KAAK,kBAAkB;AAAA,UACjE;AACA,qBAAW,QAAQ,WAAW;AAAA,QAChC;AAAA,MACF;AAAA,IACF,CAAC;AAAA,EACH;AAAA,EAEA,MAAM,QAAuB;AAvF/B;AAwFI,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,MAAM,sCAAsC;AAAA,IACxD;AAEA,QAAI,CAAC,KAAK,YAAY;AACpB,YAAM,IAAI,MAAM,uCAAuC;AAAA,IACzD;AAEA,eAAK,4BAAL;AACA,SAAK,WAAW;AAAA,EAClB;AAAA,EAEA,OAAO,OAAwB;AAC7B,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,MAAM,sCAAsC;AAAA,IACxD;AAEA,SAAK,KAAK,KAAK,KAAK;AAAA,EACtB;AAAA,EAEA,wBAAwB,OAAwB;AAC9C,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,MAAM,sCAAsC;AAAA,IACxD;AAEA,SAAK,mBAAmB,KAAK,KAAK;AAAA,EACpC;AACF;AAMO,SAAS,4BACd,yBACA;AACA,MAAI,CAAC,yBAAyB;AAC5B,WAAO,IAAI,gBAAgB;AAAA,MACzB,WAAW,OAAO,OAAO,eAAe;AACtC,mBAAW,QAAQ,KAAK;AAAA,MAC1B;AAAA,IACF,CAAC;AAAA,EACH;AACA,QAAM,UAAU,IAAI,YAAY;AAChC,QAAM,UAAU,IAAI,YAAY;AAChC,SAAO,IAAI,gBAAgB;AAAA,IACzB,WAAW,OAAO,OAAO,eAAe;AACtC,YAAM,UAAU,QAAQ,OAAO,KAAK;AACpC,iBAAW,QAAQ,QAAQ,OAAO,iBAAiB,QAAQ,OAAO,CAAC,CAAC;AAAA,IACtE;AAAA,EACF,CAAC;AACH;;;AClBA,SAAS,uBAAwD;AAC/D,MAAI,WAAW;AAEf,SAAO,UAAQ;AACb,UAAM,OAAO,KAAK,MAAM,IAAc;AAGtC,QAAI,WAAW,MAAM;AACnB,YAAM,IAAI,MAAM,GAAG,KAAK,MAAM,IAAI,KAAK,KAAK,MAAM,OAAO,EAAE;AAAA,IAC7D;AAGA,QAAI,EAAE,gBAAgB,OAAO;AAC3B;AAAA,IACF;AAMA,UAAM,OAAO,KAAK;AAClB,QACE,CAAC,YACA,KAAK,SAAS,SAAS,UAAU,KAAK,WAAW,QAAQ,GAC1D;AACA,YAAM,QAAQ,KAAK,MAAM,SAAS,MAAM;AACxC,iBAAW;AAEX,aAAO;AAAA,IACT;AAEA,WAAO;AAAA,EACT;AACF;AAEA,gBAAgB,WACd,QACA;AACA,mBAAiB,SAAS,QAAQ;AAChC,QAAI,gBAAgB,OAAO;AAEzB,YAAM,OAAO,MAAM;AACnB,UAAI;AAAM,cAAM;AAAA,IAClB,WAAW,WAAW,OAAO;AAE3B,YAAM,EAAE,MAAM,IAAI;AAClB,UAAI,UAAU,OAAO;AACnB,cAAM,OAAO,MAAM;AACnB,YAAI;AAAM,gBAAM;AAAA,MAClB;AAAA,IACF;AAAA,EACF;AACF;AAOO,SAAS,gBACd,KAIA,IACgB;AAChB,MAAI,OAAO,iBAAiB,KAAK;AAC/B,WAAO,0BAA0B,WAAW,GAAG,CAAC,EAC7C,YAAY,2BAA2B,EAAE,CAAC,EAC1C,YAAY,4BAA4B,yBAAI,uBAAuB,CAAC;AAAA,EACzE,OAAO;AACL,WAAO,SAAS,KAAK,qBAAqB,GAAG,EAAE,EAAE;AAAA,MAC/C,4BAA4B,yBAAI,uBAAuB;AAAA,IACzD;AAAA,EACF;AACF;;;ACrLO,SAAS,+BACd,EAAE,UAAU,UAAU,GACtBA,UACU;AACV,QAAM,SAAS,IAAI,eAAe;AAAA,IAChC,MAAM,MAAM,YAAY;AApB5B;AAqBM,YAAM,cAAc,IAAI,YAAY;AAEpC,YAAM,cAAc,CAAC,YAA8B;AACjD,mBAAW;AAAA,UACT,YAAY,OAAO,iBAAiB,qBAAqB,OAAO,CAAC;AAAA,QACnE;AAAA,MACF;AAEA,YAAM,kBAAkB,CAAC,YAAyB;AAChD,mBAAW;AAAA,UACT,YAAY,OAAO,iBAAiB,gBAAgB,OAAO,CAAC;AAAA,QAC9D;AAAA,MACF;AAEA,YAAM,YAAY,CAAC,iBAAyB;AAC1C,mBAAW;AAAA,UACT,YAAY,OAAO,iBAAiB,SAAS,YAAY,CAAC;AAAA,QAC5D;AAAA,MACF;AAGA,iBAAW;AAAA,QACT,YAAY;AAAA,UACV,iBAAiB,0BAA0B;AAAA,YACzC;AAAA,YACA;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAEA,UAAI;AACF,cAAMA,SAAQ;AAAA,UACZ;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH,SAAS,OAAO;AACd,mBAAW,WAAc,YAAd,YAAyB,GAAG,KAAK,EAAE;AAAA,MAChD,UAAE;AACA,mBAAW,MAAM;AAAA,MACnB;AAAA,IACF;AAAA,IACA,KAAK,YAAY;AAAA,IAAC;AAAA,IAClB,SAAS;AAAA,IAAC;AAAA,EACZ,CAAC;AAED,SAAO,IAAI,SAAS,QAAQ;AAAA,IAC1B,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,IAClB;AAAA,EACF,CAAC;AACH;;;AC7DA,gBAAgB,gBACd,UACA,2BACA;AAhBF;AAiBE,QAAM,UAAU,IAAI,YAAY;AAChC,mBAAiB,UAAS,cAAS,SAAT,YAAiB,CAAC,GAAG;AAC7C,UAAM,SAAQ,WAAM,UAAN,mBAAa;AAE3B,QAAI,SAAS,MAAM;AACjB,YAAM,YAAY,QAAQ,OAAO,KAAK;AACtC,YAAM,YAAY,KAAK,MAAM,SAAS;AACtC,YAAM,QAAQ,0BAA0B,SAAS;AAEjD,UAAI,SAAS,MAAM;AACjB,cAAM;AAAA,MACR;AAAA,IACF;AAAA,EACF;AACF;AAEO,SAAS,0BACd,UACA,WACgB;AAChB,SAAO,iBAAiB,UAAU,WAAW,WAAS,MAAM,UAAU;AACxE;AAEO,SAAS,uBACd,UACA,WACgB;AAChB,SAAO;AAAA,IACL;AAAA,IACA;AAAA;AAAA;AAAA,IAGA,WAAM;AAjDV;AAiDa,+BAAM,gBAAN,mBAAoB,OAApB,mBAAwB;AAAA;AAAA,EACnC;AACF;AAEO,SAAS,uBACd,UACA,WACgB;AAChB,SAAO,iBAAiB,UAAU,WAAW,WAAS,MAAM,UAAU;AACxE;AAEO,SAAS,iBACd,UACA,WACA,2BACA;AACA,SAAO;AAAA,IACL,gBAAgB,UAAU,yBAAyB;AAAA,EACrD,EACG,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,IACC,4BAA4B,uCAAW,uBAAuB;AAAA,EAChE;AACJ;;;ACjEA,IAAM,cAAc,IAAI,YAAY,OAAO;AAe3C,eAAe,aACb,OACA,YACA;AACA,aAAW,QAAQ,OAAO;AACxB,UAAM,EAAE,MAAM,YAAY,IAAI,KAAK,MAAM,IAAI;AAG7C,QAAI,CAAC,aAAa;AAChB,iBAAW,QAAQ,IAAI;AAAA,IACzB;AAAA,EACF;AACF;AAEA,eAAe,oBACb,QACA,YACA;AACA,MAAI,UAAU;AAEd,SAAO,MAAM;AACX,UAAM,EAAE,OAAO,OAAO,KAAK,IAAI,MAAM,OAAO,KAAK;AACjD,QAAI,MAAM;AACR;AAAA,IACF;AAEA,eAAW,YAAY,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAErD,UAAM,aAAa,QAAQ,MAAM,aAAa;AAC9C,cAAU,WAAW,IAAI,KAAK;AAE9B,UAAM,aAAa,YAAY,UAAU;AAAA,EAC3C;AAEA,MAAI,SAAS;AACX,UAAM,aAAa,CAAC,OAAO;AAC3B,UAAM,aAAa,YAAY,UAAU;AAAA,EAC3C;AAEA,aAAW,MAAM;AACnB;AAEA,SAASC,cAAa,KAAe;AAhErC;AAiEE,QAAM,UAAS,SAAI,SAAJ,mBAAU;AAEzB,SAAO,IAAI,eAAuB;AAAA,IAChC,MAAM,MAAM,YAA2B;AACrC,UAAI,CAAC,QAAQ;AACX,mBAAW,MAAM;AACjB;AAAA,MACF;AAEA,YAAM,oBAAoB,QAAQ,UAAU;AAAA,IAC9C;AAAA,EACF,CAAC;AACH;AAEA,gBAAgBC,YAAW,QAAoC;AAC7D,mBAAiB,SAAS,QAAQ;AAChC,QAAI,MAAM,cAAc,mBAAmB;AACzC,YAAM,OAAO,MAAM;AACnB,UAAI;AAAM,cAAM;AAAA,IAClB;AAAA,EACF;AACF;AAEO,SAAS,aACd,QACA,WACgB;AAChB,MAAI,OAAO,iBAAiB,QAAQ;AAClC,WAAO,0BAA0BA,YAAW,MAAM,CAAC,EAChD,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,MACC,4BAA4B,uCAAW,uBAAuB;AAAA,IAChE;AAAA,EACJ,OAAO;AACL,WAAOD,cAAa,MAAM,EACvB,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,MACC,4BAA4B,uCAAW,uBAAuB;AAAA,IAChE;AAAA,EACJ;AACF;;;ACzEA,gBAAgBE,YAAW,UAExB;AAlCH;AAmCE,mBAAiB,SAAS,SAAS,QAAQ;AACzC,UAAM,SAAQ,uBAAM,eAAN,mBAAmB,OAAnB,mBAAuB,YAAvB,mBAAgC;AAE9C,QAAI,UAAU,QAAW;AACvB;AAAA,IACF;AAEA,UAAM,YAAY,MAAM,CAAC;AAEzB,QAAI,OAAO,UAAU,SAAS,UAAU;AACtC,YAAM,UAAU;AAAA,IAClB;AAAA,EACF;AACF;AAEO,SAAS,yBACd,UAGA,IACgB;AAChB,SAAO,0BAA0BA,YAAW,QAAQ,CAAC,EAClD,YAAY,2BAA2B,EAAE,CAAC,EAC1C,YAAY,4BAA4B,yBAAI,uBAAuB,CAAC;AACzE;;;ACpDA,SAASC,cAAa,KAA0B;AAC9C,QAAM,oBAAoB,wBAAwB;AAClD,SAAO,IAAI,eAAuB;AAAA,IAChC,MAAM,KAAK,YAA2B;AAV1C;AAWM,YAAM,EAAE,OAAO,KAAK,IAAI,MAAM,IAAI,KAAK;AAEvC,UAAI,MAAM;AACR,mBAAW,MAAM;AACjB;AAAA,MACF;AAEA,YAAM,OAAO,mBAAkB,iBAAM,UAAN,mBAAa,SAAb,YAAqB,EAAE;AACtD,UAAI,CAAC;AAAM;AAGX,UAAI,MAAM,kBAAkB,QAAQ,MAAM,eAAe,SAAS,GAAG;AACnE;AAAA,MACF;AAKA,UAAI,SAAS,UAAU,SAAS,mBAAmB,SAAS,WAAW;AACrE;AAAA,MACF;AAEA,iBAAW,QAAQ,IAAI;AAAA,IACzB;AAAA,EACF,CAAC;AACH;AAEO,SAAS,kBACd,KACA,WACgB;AAChB,SAAOA,cAAa,GAAG,EACpB,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,IACC,4BAA4B,uCAAW,uBAAuB;AAAA,EAChE;AACJ;;;ACrBO,SAAS,aACd,KACA,WACgB;AAChB,MAAI,CAAC,IAAI,MAAM;AACb,UAAM,IAAI,MAAM,uBAAuB;AAAA,EACzC;AAEA,MAAI,kBAAkB;AACtB,MAAI;AAEJ,QAAM,oBAAoC,CAAC,MAAc,YAAY;AArCvE;AAsCI,UAAM,EAAE,MAAM,IAAI;AAElB,QAAI,UAAU,iBAAiB;AAC7B,sBAAgB,KAAK,MAAM,IAAI;AAC/B,mDAAW,mBAAX,mCAA4B;AAAA,IAC9B;AAEA,QAAI,UAAU,iBAAiB;AAC7B,YAAM,qBAAqB,KAAK,MAAM,IAAI;AAC1C,yBAAkB,wBAAmB,oBAAnB,YAAsC;AACxD,aAAO,mBAAmB;AAAA,IAC5B;AACA;AAAA,EACF;AAEA,MAAI,EAAE,gBAAgB,GAAG,qBAAqB,IAAI,aAAa,CAAC;AAGhE,yBAAuB;AAAA,IACrB,GAAG;AAAA,IACH,SAAS,gBAAc;AA1D3B;AA2DM,YAAM,wBAA+C;AAAA,QACnD;AAAA,QACA;AAAA,MACF;AACA,mDAAW,YAAX,mCAAqB,YAAY;AAAA,IACnC;AAAA,EACF;AAEA,SAAO,SAAS,KAAK,mBAAmB,oBAAoB,EAAE;AAAA,IAC5D,4BAA4B,6DAAsB,uBAAuB;AAAA,EAC3E;AACF;;;AChEO,SAAS,gBAAgB,WAAyC;AACvE,QAAM,SAAS,IAAI,gBAAgB;AACnC,QAAM,SAAS,OAAO,SAAS,UAAU;AAEzC,QAAM,OAAO,oBAAI,IAAI;AAErB,QAAM,cAAc,OAAO,GAAU,UAAkB;AACrD,SAAK,OAAO,KAAK;AACjB,UAAM,OAAO;AACb,UAAM,OAAO,MAAM,CAAC;AAAA,EACtB;AAEA,QAAM,cAAc,OAAO,UAAkB;AAC3C,SAAK,IAAI,KAAK;AAAA,EAChB;AAEA,QAAM,YAAY,OAAO,UAAkB;AACzC,SAAK,OAAO,KAAK;AAEjB,QAAI,KAAK,SAAS,GAAG;AACnB,YAAM,OAAO;AACb,YAAM,OAAO,MAAM;AAAA,IACrB;AAAA,EACF;AAEA,SAAO;AAAA,IACL,QAAQ,OAAO,SACZ,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,MACC,4BAA4B,uCAAW,uBAAuB;AAAA,IAChE;AAAA,IACF;AAAA,IACA,UAAU;AAAA,MACR,mBAAmB,OAAO,UAAkB;AAC1C,cAAM,OAAO;AACb,cAAM,OAAO,MAAM,KAAK;AAAA,MAC1B;AAAA,MACA,gBAAgB,OAAO,MAAW,UAAoB,UAAkB;AACtE,oBAAY,KAAK;AAAA,MACnB;AAAA,MACA,cAAc,OAAO,SAAc,UAAkB;AACnD,cAAM,UAAU,KAAK;AAAA,MACvB;AAAA,MACA,gBAAgB,OAAO,GAAU,UAAkB;AACjD,cAAM,YAAY,GAAG,KAAK;AAAA,MAC5B;AAAA,MACA,kBAAkB,OAAO,QAAa,SAAc,UAAkB;AACpE,oBAAY,KAAK;AAAA,MACnB;AAAA,MACA,gBAAgB,OAAO,UAAe,UAAkB;AACtD,cAAM,UAAU,KAAK;AAAA,MACvB;AAAA,MACA,kBAAkB,OAAO,GAAU,UAAkB;AACnD,cAAM,YAAY,GAAG,KAAK;AAAA,MAC5B;AAAA,MACA,iBAAiB,OAAO,OAAY,QAAgB,UAAkB;AACpE,oBAAY,KAAK;AAAA,MACnB;AAAA,MACA,eAAe,OAAO,SAAiB,UAAkB;AACvD,cAAM,UAAU,KAAK;AAAA,MACvB;AAAA,MACA,iBAAiB,OAAO,GAAU,UAAkB;AAClD,cAAM,YAAY,GAAG,KAAK;AAAA,MAC5B;AAAA,IACF;AAAA,EACF;AACF;;;AChEA,gBAAgBC,YAAW,QAAoD;AAR/E;AASE,mBAAiB,SAAS,QAAQ;AAChC,UAAM,WAAU,iBAAM,QAAQ,CAAC,MAAf,mBAAkB,UAAlB,mBAAyB;AAEzC,QAAI,YAAY,UAAa,YAAY,IAAI;AAC3C;AAAA,IACF;AAEA,UAAM;AAAA,EACR;AACF;AAEO,SAAS,cACd,UACA,WACgB;AAChB,QAAM,SAAS,0BAA0BA,YAAW,QAAQ,CAAC;AAC7D,SAAO,OACJ,YAAY,2BAA2B,SAAS,CAAC,EACjD;AAAA,IACC,4BAA4B,uCAAW,uBAAuB;AAAA,EAChE;AACJ;;;ACgPA,SAAS,oBAE+C;AACtD,QAAM,UAAU,YAAY;AAC5B,SAAO,UAAQ,QAAQ,KAAK,MAAM,IAAI,CAA4B;AACpE;AAOA,gBAAgBC,YAAW,QAA8C;AACvE,QAAM,UAAU,YAAY;AAE5B,iBAAe,SAAS,QAAQ;AAG9B,QAAI,yBAAyB,OAAO;AAClC,cAAQ;AAAA,QACN,IAAI,MAAM;AAAA,QACV,SAAS,MAAM,QAAQ,QAAQ;AAAA,QAC/B,QAAS,MAAc;AAAA;AAAA,QACvB,OAAQ,MAAc;AAAA;AAAA,QACtB,SAAS,MAAM,QAAQ,IAAI,YAAO;AAtS1C;AAsS8C;AAAA,YACpC,OAAO;AAAA,cACL,UAAS,YAAO,UAAP,mBAAc;AAAA,cACvB,gBAAe,YAAO,UAAP,mBAAc;AAAA,cAC7B,OAAM,YAAO,UAAP,mBAAc;AAAA,cACpB,cAAY,kBAAO,UAAP,mBAAc,cAAd,mBAAyB,WACjC,kBAAO,UAAP,mBAAc,cAAd,mBAAyB,IAAI,CAAC,UAAU,WAAW;AAAA,gBACjD;AAAA,gBACA,IAAI,SAAS;AAAA,gBACb,UAAU,SAAS;AAAA,gBACnB,MAAM,SAAS;AAAA,cACjB,MACA;AAAA,YACN;AAAA,YACA,eAAe,OAAO;AAAA,YACtB,OAAO,OAAO;AAAA,UAChB;AAAA,SAAE;AAAA,MACJ;AAAA,IACF;AAEA,UAAM,OAAO,QAAQ,KAAK;AAE1B,QAAI;AAAM,YAAM;AAAA,EAClB;AACF;AAEA,SAAS,cAE+C;AACtD,QAAM,oBAAoB,wBAAwB;AAClD,MAAI;AACJ,SAAO,UAAQ;AArUjB;AAsUI,QAAI,sBAAsB,IAAI,GAAG;AAC/B,YAAM,SAAQ,UAAK,QAAQ,CAAC,MAAd,mBAAiB;AAC/B,WAAI,WAAM,kBAAN,mBAAqB,MAAM;AAC7B,gCAAwB;AACxB,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,SAAS,+BAA+B,MAAM,cAAc,IAAI;AAAA,QAClE;AAAA,MACF,YAAW,uBAAM,eAAN,mBAAmB,OAAnB,mBAAuB,aAAvB,mBAAiC,MAAM;AAChD,gCAAwB;AACxB,cAAM,WAAW,MAAM,WAAW,CAAC;AACnC,YAAI,SAAS,UAAU,GAAG;AACxB,iBAAO;AAAA,YACL,QAAQ;AAAA,YACR,SAAS,2BAA2B,SAAS,EAAE,iDAAgD,cAAS,aAAT,mBAAmB,IAAI;AAAA,UACxH;AAAA,QACF,OAAO;AACL,iBAAO;AAAA,YACL,QAAQ;AAAA,YACR,SAAS,gBAAgB,SAAS,EAAE,iDAAgD,cAAS,aAAT,mBAAmB,IAAI;AAAA,UAC7G;AAAA,QACF;AAAA,MACF,YAAW,WAAM,kBAAN,mBAAqB,WAAW;AACzC,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,SAAS,kBAAiB,WAAM,kBAAN,mBAAqB,SAAS;AAAA,QAC1D;AAAA,MACF,YAAW,uBAAM,eAAN,mBAAmB,OAAnB,mBAAuB,aAAvB,mBAAiC,WAAW;AACrD,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,SAAS,kBAAiB,uBAAM,eAAN,mBAAmB,OAAnB,mBAAuB,aAAvB,mBAAiC,SAAS;AAAA,QACtE;AAAA,MACF,WACE,4BACC,UAAK,QAAQ,CAAC,MAAd,mBAAiB,mBAAkB,qBAClC,UAAK,QAAQ,CAAC,MAAd,mBAAiB,mBAAkB,SACrC;AACA,gCAAwB;AACxB,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,SAAS;AAAA,QACX;AAAA,MACF,WACE,2BACA,UAAK,QAAQ,CAAC,MAAd,mBAAiB,mBAAkB,cACnC;AACA,gCAAwB;AACxB,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,SAAS;AAAA,QACX;AAAA,MACF;AAAA,IACF;AAEA,UAAM,OAAO;AAAA,MACX,sBAAsB,IAAI,KAAK,KAAK,QAAQ,CAAC,EAAE,MAAM,UACjD,KAAK,QAAQ,CAAC,EAAE,MAAM,UACtB,aAAa,IAAI,IACjB,KAAK,QAAQ,CAAC,EAAE,OAChB;AAAA,IACN;AAEA,WAAO;AAAA,EACT;AAEA,WAAS,iBAAiB,eAAuB;AAC/C,QAAI,qBAAqB,cACtB,QAAQ,OAAO,MAAM,EACrB,QAAQ,OAAO,KAAK,EACpB,QAAQ,MAAM,KAAK,EACnB,QAAQ,OAAO,KAAK,EACpB,QAAQ,OAAO,KAAK,EACpB,QAAQ,OAAO,KAAK,EACpB,QAAQ,OAAO,KAAK;AAEvB,WAAO,GAAG,kBAAkB;AAAA,EAC9B;AACF;AAEA,IAAM,qCAAqC;AAAA,EACzC;AACF;AAYA,SAAS,sBACP,MAC6B;AAC7B,SACE,aAAa,QACb,KAAK,WACL,KAAK,QAAQ,CAAC,KACd,WAAW,KAAK,QAAQ,CAAC;AAE7B;AAEA,SAAS,aAAa,MAAmD;AACvE,SACE,aAAa,QACb,KAAK,WACL,KAAK,QAAQ,CAAC,KACd,UAAU,KAAK,QAAQ,CAAC;AAE5B;AAEO,SAAS,aACd,KACA,WACgB;AAEhB,QAAM,KAIG;AAET,MAAI;AACJ,MAAI,OAAO,iBAAiB,KAAK;AAC/B,aAAS,0BAA0BA,YAAW,GAAG,CAAC,EAAE;AAAA,MAClD;AAAA,SACE,yBAAI,iCAA+B,yBAAI,2BACnC;AAAA,UACE,GAAG;AAAA,UACH,SAAS;AAAA,QACX,IACA;AAAA,UACE,GAAG;AAAA,QACL;AAAA,MACN;AAAA,IACF;AAAA,EACF,OAAO;AACL,aAAS;AAAA,MACP;AAAA,MACA,kBAAkB;AAAA,OAClB,yBAAI,iCAA+B,yBAAI,2BACnC;AAAA,QACE,GAAG;AAAA,QACH,SAAS;AAAA,MACX,IACA;AAAA,QACE,GAAG;AAAA,MACL;AAAA,IACN;AAAA,EACF;AAEA,MAAI,OAAO,GAAG,+BAA+B,GAAG,0BAA0B;AACxE,UAAM,0BAA0B,8BAA8B,EAAE;AAChE,WAAO,OAAO,YAAY,uBAAuB;AAAA,EACnD,OAAO;AACL,WAAO,OAAO;AAAA,MACZ,4BAA4B,yBAAI,uBAAuB;AAAA,IACzD;AAAA,EACF;AACF;AAEA,SAAS,8BACP,WAGyC;AACzC,QAAM,cAAc,IAAI,YAAY;AACpC,MAAI,eAAe;AACnB,MAAI,qBAAqB;AACzB,MAAI,oCAAoC;AACxC,MAAI,wBAAwB;AAE5B,MAAI,uBACF,UAAU,kCAAkC,KAAK,CAAC;AAEpD,QAAM,gBAAgB,uCAAW;AACjC,QAAM,SAAS,mBAAmB;AAElC,SAAO,IAAI,gBAAgB;AAAA,IACzB,MAAM,UAAU,OAAO,YAA2B;AAChD,YAAM,UAAU,OAAO,KAAK;AAC5B,2CAAqC;AAErC,YAAM,yBACJ,iBACC,QAAQ,WAAW,mBAAmB,KACrC,QAAQ,WAAW,gBAAgB;AAEvC,UAAI,wBAAwB;AAC1B,gCAAwB;AACxB,8BAAsB;AACtB,uBAAe;AACf;AAAA,MACF;AAGA,UAAI,CAAC,uBAAuB;AAC1B,mBAAW;AAAA,UACT,gBACI,YAAY,OAAO,iBAAiB,QAAQ,OAAO,CAAC,IACpD;AAAA,QACN;AACA;AAAA,MACF,OAAO;AACL,8BAAsB;AAAA,MACxB;AAAA,IACF;AAAA,IACA,MAAM,MAAM,YAA2B;AACrC,UAAI;AACF,YACE,CAAC,gBACD,0BACC,UAAU,+BACT,UAAU,0BACZ;AACA,kCAAwB;AACxB,gBAAM,UAAU,KAAK,MAAM,kBAAkB;AAE7C,cAAI,0BAA2C;AAAA,YAC7C,GAAG;AAAA,UACL;AAEA,cAAI,mBAMY;AAEhB,cAAI,UAAU,6BAA6B;AAIzC,gBAAI,QAAQ,kBAAkB,QAAW;AACvC,sBAAQ;AAAA,gBACN;AAAA,cACF;AAAA,YACF;AAEA,kBAAM,mBAAmB,KAAK;AAAA,cAC5B,QAAQ,cAAc;AAAA,YACxB;AAEA,+BAAmB,MAAM,UAAU;AAAA,cACjC;AAAA,gBACE,MAAM,QAAQ,cAAc;AAAA,gBAC5B,WAAW;AAAA,cACb;AAAA,cACA,YAAU;AAER,0CAA0B;AAAA,kBACxB,GAAG;AAAA,kBACH;AAAA,oBACE,MAAM;AAAA,oBACN,SAAS;AAAA,oBACT,eAAe,QAAQ;AAAA,kBACzB;AAAA,kBACA;AAAA,oBACE,MAAM;AAAA,oBACN,MAAM,QAAQ,cAAc;AAAA,oBAC5B,SAAS,KAAK,UAAU,MAAM;AAAA,kBAChC;AAAA,gBACF;AAEA,uBAAO;AAAA,cACT;AAAA,YACF;AAAA,UACF;AACA,cAAI,UAAU,yBAAyB;AACrC,kBAAM,YAA6B;AAAA,cACjC,OAAO,CAAC;AAAA,YACV;AACA,uBAAW,QAAQ,QAAQ,YAAY;AACrC,wBAAU,MAAM,KAAK;AAAA,gBACnB,IAAI,KAAK;AAAA,gBACT,MAAM;AAAA,gBACN,MAAM;AAAA,kBACJ,MAAM,KAAK,SAAS;AAAA,kBACpB,WAAW,KAAK,MAAM,KAAK,SAAS,SAAS;AAAA,gBAC/C;AAAA,cACF,CAAC;AAAA,YACH;AACA,gBAAI,gBAAgB;AACpB,gBAAI;AACF,iCAAmB,MAAM,UAAU;AAAA,gBACjC;AAAA,gBACA,YAAU;AACR,sBAAI,QAAQ;AACV,0BAAM,EAAE,cAAc,eAAe,iBAAiB,IACpD;AAEF,8CAA0B;AAAA,sBACxB,GAAG;AAAA;AAAA,sBAEH,GAAI,kBAAkB,IAClB;AAAA,wBACE;AAAA,0BACE,MAAM;AAAA,0BACN,SAAS;AAAA,0BACT,YAAY,QAAQ,WAAW;AAAA,4BAC7B,CAAC,QAAkB;AAAA,8BACjB,IAAI,GAAG;AAAA,8BACP,MAAM;AAAA,8BACN,UAAU;AAAA,gCACR,MAAM,GAAG,SAAS;AAAA;AAAA,gCAElB,WAAW,KAAK;AAAA,kCACd,GAAG,SAAS;AAAA,gCACd;AAAA,8BACF;AAAA,4BACF;AAAA,0BACF;AAAA,wBACF;AAAA,sBACF,IACA,CAAC;AAAA;AAAA,sBAEL;AAAA,wBACE,MAAM;AAAA,wBACN;AAAA,wBACA,MAAM;AAAA,wBACN,SAAS,KAAK,UAAU,gBAAgB;AAAA,sBAC1C;AAAA,oBACF;AACA;AAAA,kBACF;AAEA,yBAAO;AAAA,gBACT;AAAA,cACF;AAAA,YACF,SAAS,GAAG;AACV,sBAAQ,MAAM,0CAA0C,CAAC;AAAA,YAC3D;AAAA,UACF;AAEA,cAAI,CAAC,kBAAkB;AAIrB,uBAAW;AAAA,cACT,YAAY;AAAA,gBACV,gBACI;AAAA,kBACE,QAAQ,gBAAgB,kBAAkB;AAAA;AAAA,kBAE1C,KAAK,MAAM,kBAAkB;AAAA,gBAC/B,IACA;AAAA,cACN;AAAA,YACF;AACA;AAAA,UACF,WAAW,OAAO,qBAAqB,UAAU;AAE/C,uBAAW;AAAA,cACT,gBACI,YAAY,OAAO,iBAAiB,QAAQ,gBAAgB,CAAC,IAC7D,YAAY,OAAO,gBAAgB;AAAA,YACzC;AACA,gDAAoC;AACpC;AAAA,UACF;AAOA,gBAAM,oBAA2C;AAAA,YAC/C,GAAG;AAAA,YACH,SAAS;AAAA,UACX;AAEA,oBAAU,UAAU;AAEpB,gBAAM,eAAe,aAAa,kBAAkB;AAAA,YAClD,GAAG;AAAA,YACH,CAAC,kCAAkC,GAAG;AAAA,UACxC,CAAgC;AAEhC,gBAAM,SAAS,aAAa,UAAU;AAEtC,iBAAO,MAAM;AACX,kBAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,gBAAI,MAAM;AACR;AAAA,YACF;AACA,uBAAW,QAAQ,KAAK;AAAA,UAC1B;AAAA,QACF;AAAA,MACF,UAAE;AACA,YAAI,UAAU,WAAW,mCAAmC;AAC1D,gBAAM,UAAU,QAAQ,iCAAiC;AAAA,QAC3D;AAAA,MACF;AAAA,IACF;AAAA,EACF,CAAC;AACH;;;ACrqBA,eAAsB,gBACpB,KACA,IACA,SAGyB;AArD3B;AAsDE,QAAM,OAAM,SAAI,SAAJ,mBAAU;AAEtB,MAAI,CAAC,KAAK;AACR,QAAI,IAAI;AAAO,YAAM,IAAI,MAAM,IAAI,KAAK;AAAA;AACnC,YAAM,IAAI,MAAM,0CAA0C;AAAA,EACjE;AAEA,QAAM,cAAc,MAAM,MAAM,KAAK;AAAA,IACnC,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,QAAQ;AAAA,MACR,GAAG,mCAAS;AAAA,IACd;AAAA,EACF,CAAC;AAED,SAAO,SAAS,aAAa,QAAW,EAAE,EAAE;AAAA,IAC1C,4BAA4B,yBAAI,uBAAuB;AAAA,EACzD;AACF;;;ACtEA,IAAM,UAAU,KAAK,WAAW,CAAC;AAGjC,SAAS,aAAa,QAAsB,aAAqB;AAC/D,QAAM,qBAAqB,IAAI,WAAW,WAAW;AAErD,MAAI,SAAS;AACb,aAAW,SAAS,QAAQ;AAC1B,uBAAmB,IAAI,OAAO,MAAM;AACpC,cAAU,MAAM;AAAA,EAClB;AACA,SAAO,SAAS;AAEhB,SAAO;AACT;AAEA,gBAAuB,eACrB,QACA;AAAA,EACE;AACF,IAEI,CAAC,GAC2B;AAIhC,QAAM,UAAU,IAAI,YAAY;AAChC,QAAM,SAAuB,CAAC;AAC9B,MAAI,cAAc;AAElB,SAAO,MAAM;AACX,UAAM,EAAE,MAAM,IAAI,MAAM,OAAO,KAAK;AAEpC,QAAI,OAAO;AACT,aAAO,KAAK,KAAK;AACjB,qBAAe,MAAM;AACrB,UAAI,MAAM,MAAM,SAAS,CAAC,MAAM,SAAS;AAEvC;AAAA,MACF;AAAA,IACF;AAEA,QAAI,OAAO,WAAW,GAAG;AACvB;AAAA,IACF;AAEA,UAAM,qBAAqB,aAAa,QAAQ,WAAW;AAC3D,kBAAc;AAEd,UAAMC,eAAc,QACjB,OAAO,oBAAoB,EAAE,QAAQ,KAAK,CAAC,EAC3C,MAAM,IAAI,EACV,OAAO,UAAQ,SAAS,EAAE,EAC1B,IAAI,eAAe;AAEtB,eAAW,cAAcA,cAAa;AACpC,YAAM;AAAA,IACR;AAGA,QAAI,0CAAe;AACjB,aAAO,OAAO;AACd;AAAA,IACF;AAAA,EACF;AACF;;;ACnDA,SAAS,2BACP,SACA,aACG;AACH,MAAI,CAAC,WAAW,CAAC,eAAe,CAAC,YAAY;AAAQ,WAAO;AAC5D,SAAO,EAAE,GAAG,SAAS,aAAa,CAAC,GAAG,WAAW,EAAE;AACrD;AAEA,eAAsB,qBAAqB;AAAA,EACzC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,aAAa;AAAA,EACb,iBAAiB,MAAM,oBAAI,KAAK;AAClC,GASG;AACD,QAAM,YAAY,eAAe;AACjC,QAAM,YAAuB;AAAA,IAC3B,MAAM,CAAC;AAAA,EACT;AAGA,MAAI,sBAA+C;AAGnD,mBAAiB,EAAE,MAAM,MAAM,KAAK,eAAe,QAAQ;AAAA,IACzD,WAAW,OAAM,yDAAoB,aAAY;AAAA,EACnD,CAAC,GAAG;AACF,QAAI,SAAS,QAAQ;AACnB,UAAI,UAAU,MAAM,GAAG;AACrB,kBAAU,MAAM,IAAI;AAAA,UAClB,GAAG,UAAU,MAAM;AAAA,UACnB,UAAU,UAAU,MAAM,EAAE,WAAW,MAAM;AAAA,QAC/C;AAAA,MACF,OAAO;AACL,kBAAU,MAAM,IAAI;AAAA,UAClB,IAAI,WAAW;AAAA,UACf,MAAM;AAAA,UACN,SAAS;AAAA,UACT;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,QAAI,sBAAkD;AAEtD,QAAI,SAAS,iBAAiB;AAC5B,gBAAU,eAAe,IAAI;AAAA,QAC3B,IAAI,WAAW;AAAA,QACf,MAAM;AAAA,QACN,SAAS;AAAA,QACT,eAAe,MAAM;AAAA,QACrB,MAAM,MAAM,cAAc;AAAA,QAC1B;AAAA,MACF;AAEA,4BAAsB,UAAU,eAAe;AAAA,IACjD;AAEA,QAAI,kBAA8C;AAElD,QAAI,SAAS,cAAc;AACzB,gBAAU,YAAY,IAAI;AAAA,QACxB,IAAI,WAAW;AAAA,QACf,MAAM;AAAA,QACN,SAAS;AAAA,QACT,YAAY,MAAM;AAAA,QAClB;AAAA,MACF;AAEA,wBAAkB,UAAU,YAAY;AAAA,IAC1C;AAEA,QAAI,SAAS,QAAQ;AACnB,gBAAU,MAAM,EAAE,KAAK,GAAG,KAAK;AAAA,IACjC;AAEA,QAAI,kBAAkB,UAAU,MAAM;AAEtC,QAAI,SAAS,uBAAuB;AAClC,UAAI,CAAC,qBAAqB;AACxB,8BAAsB,CAAC,GAAG,KAAK;AAAA,MACjC,OAAO;AACL,4BAAoB,KAAK,GAAG,KAAK;AAAA,MACnC;AAGA,4BAAsB;AAAA,QACpB,UAAU,eAAe;AAAA,QACzB;AAAA,MACF;AACA,wBAAkB;AAAA,QAChB,UAAU,YAAY;AAAA,QACtB;AAAA,MACF;AACA,wBAAkB;AAAA,QAChB,UAAU,MAAM;AAAA,QAChB;AAAA,MACF;AAAA,IACF;AAGA,QAAI,2DAAqB,QAAQ;AAC/B,YAAM,oBAAyC;AAAA,QAC7C;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,wBAAkB,QAAQ,SAAO;AAC/B,YAAI,UAAU,GAAG,GAAG;AAClB,UAAC,UAAU,GAAG,EAAc,cAAc,CAAC,GAAG,mBAAoB;AAAA,QACpE;AAAA,MACF,CAAC;AAAA,IACH;AAGA,UAAM,SAAS,CAAC,qBAAqB,iBAAiB,eAAe,EAClE,OAAO,OAAO,EACd,IAAI,cAAY;AAAA,MACf,GAAG,2BAA2B,SAAS,mBAAmB;AAAA,IAC5D,EAAE;AAEJ,WAAO,QAAQ,CAAC,GAAG,UAAU,MAAM,CAAC,CAAC;AAAA,EACvC;AAEA,uCAAW;AAEX,SAAO;AAAA,IACL,UAAU;AAAA,MACR,UAAU;AAAA,MACV,UAAU;AAAA,MACV,UAAU;AAAA,IACZ,EAAE,OAAO,OAAO;AAAA,IAChB,MAAM,UAAU;AAAA,EAClB;AACF;;;ACpIO,IAAM,sCAAN,MAA0C;AAAA,EAC/C,YACE,KACA,SAQA;AAxCJ;AAyCI,QAAI,cAA+C,MAAM;AAAA,IAAC;AAC1D,QAAI,OAAO,IAAI,QAA0B,aAAW;AAClD,oBAAc;AAAA,IAChB,CAAC;AAED,QAAI,mCAAS,MAAM;AACjB,YAAM,kBAA8C,IAAI;AAAA,QACtD,QAAQ,KAAK;AAAA,MACf;AAEA,UAAI,cAAmC;AAGvC,2BAAqB;AAAA,QACnB,QAAQ,gBAAgB,UAAU;AAAA,QAClC,QAAQ,CAAC,QAAQ,SAAS;AAxDlC,cAAAC,KAAA;AAyDU,gBAAMC,YAAU,MAAAD,MAAA,OAAO,CAAC,MAAR,gBAAAA,IAAW,YAAX,YAAsB;AACtC,gBAAM,OAAK,wCAAS,OAAT,iCAAc,EAAE,SAAAC,UAAS,KAAK,OAAMA;AAC/C,gBAAM,UAAmB,EAAE,IAAI,SAAAA,SAAQ;AAEvC,gBAAM,kBAAkB;AACxB,gBAAM,UAAU,IAAI,QAA0B,aAAW;AACvD,0BAAc;AAAA,UAChB,CAAC;AAED,0BAAgB;AAAA,YACd,MAAM;AAAA,YACN,GAAG;AAAA,UACL,CAAC;AAED,wBAAc;AAAA,QAChB;AAAA,QACA,aAAY,aAAQ,eAAR,YAAsB;AAAA,QAClC,UAAU,MAAM;AAGd,cAAI,gBAAgB,QAAW;AAC7B,wBAAY;AAAA,cACV,MAAM;AAAA,cACN,GAAG;AAAA,YACL,CAAC;AAAA,UACH;AAAA,QACF;AAAA,MACF,CAAC;AAED,aAAO;AAAA,IACT;AAEA,QAAI,UAAU;AAEd,UAAM,SAAS,mBAAmB;AAClC,UAAM,SAAS,IAAI,UAAU;AAC7B,mBAAe,YAAY;AA7F/B,UAAAD;AA8FM,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,CAAC,MAAM;AACT,mBAAW,OAAO,KAAK;AAAA,MACzB;AAKA,YAAM,OAAKA,MAAA,mCAAS,OAAT,gBAAAA,IAAA,cAAc,EAAE,QAAQ,OAAM;AAEzC,YAAM,UAAmB;AAAA,QACvB;AAAA,QACA;AAAA,MACF;AAEA,YAAM,kBAAkB;AACxB,YAAM,UAAU,OACZ,OACA,IAAI,QAA0B,aAAW;AACvC,sBAAc;AAAA,MAChB,CAAC;AACL,sBAAgB;AAAA,QACd,MAAM;AAAA,QACN,GAAG;AAAA,MACL,CAAC;AAED,UAAI,MAAM;AACR;AAAA,MACF;AAEA,YAAM,UAAU;AAAA,IAClB;AACA,cAAU;AAEV,WAAO;AAAA,EACT;AACF;;;AC3HO,IAAM,wBAAN,cAAoC,SAAS;AAAA,EAClD,YACE,KACA,MACA,MACA;AACA,QAAI,kBAAkB;AAEtB,QAAI,MAAM;AACR,wBAAkB,IAAI,YAAY,KAAK,MAAM;AAAA,IAC/C;AAEA,UAAM,iBAAwB;AAAA,MAC5B,GAAG;AAAA,MACH,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,CAAC,cAAc,GAAG,OAAO,SAAS;AAAA,QAClC,GAAG,6BAAM;AAAA,MACX;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAKO,SAAS,iBACd,KACA,UACA,MACA;AACA,WAAS,WAAU,6BAAM,WAAU,KAAK;AAAA,IACtC,gBAAgB;AAAA,IAChB,GAAG,6BAAM;AAAA,EACX,CAAC;AAED,QAAM,SAAS,IAAI,UAAU;AAC7B,WAAS,OAAO;AACd,WAAO,KAAK,EAAE,KAAK,CAAC,EAAE,MAAM,MAAM,MAAsC;AACtE,UAAI,MAAM;AACR,iBAAS,IAAI;AACb;AAAA,MACF;AACA,eAAS,MAAM,KAAK;AACpB,WAAK;AAAA,IACP,CAAC;AAAA,EACH;AACA,OAAK;AACP;","names":["process","createParser","streamable","streamable","createParser","streamable","streamable","streamParts","_a","content"]}